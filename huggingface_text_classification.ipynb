{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LizzieChall/huggingface_food_not_food_text_classification_demo/blob/main/huggingface_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCl4VtZOub7y"
      },
      "source": [
        "# Text Classification with Hugging Face Transformers.\n",
        "\n",
        "Welcome to the Hugging Face Text Classification project!\n",
        "\n",
        "Weâ€™re going to be bulding a `food/not_food` **text classification model.**\n",
        "\n",
        "Given a piece of a text (such as an image caption), our model will be able to predict if itâ€™s about food or not.\n",
        "\n",
        "Weâ€™re going to start with a text dataset, build a model to classify text samples and then share our model as a demo others can use.\n",
        "\n",
        "To do so, weâ€™ll be using a handful of helpful open-source tools from the Hugging Face ecosystem.\n",
        "\n",
        "Weâ€™re going to follow the workflow of:\n",
        "\n",
        "1. Create and preprocess data.\n",
        "2. Define the model weâ€™d like to use with [transformers.AutoModelForSequenceClassification](https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoModelForSequenceClassification) (or another similar model class).\n",
        "3. Define training arguments (these are hyperparameters for our model) with [transformers.TrainingArguments.](https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments)\n",
        "4. Pass `TrainingArguments` from 3 and target datasets to an instance of [transformers.Trainer.](https://huggingface.co/docs/transformers/en/main_classes/trainer)\n",
        "5. Train the model by calling [Trainer.train().](https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.Trainer.train)\n",
        "6. Save the model (to our local machine or to the Hugging Face Hub).\n",
        "7. Evaluate the trained model by making and inspecting predctions on the test data.\n",
        "8. Turn the model into a shareable demo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFukpYD42_FE"
      },
      "source": [
        "## Importing the necessary libraries.\n",
        "\n",
        "Weâ€™ll need to install the following libraries from the Hugging Face ecosystem:\n",
        "\n",
        "* Transformers - comes pre-installed on Google Colab.\n",
        "* Datasets - a library for accessing and manipulating datasets on and off the Hugging Face Hub, we can install it via `pip install datasets`.\n",
        "* Evaluate - a library for evaluating machine learning model performance with various metrics, we can install it via `pip install evaluate`.\n",
        "* Accelerate - a library for training machine learning models faster, we can install it via `pip install accelerate`.\n",
        "* Gradio - a library for creating interactive demos of machine learning models, we can install it via `pip install gradio`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwEeNMOst5t0",
        "outputId": "afba1390-432a-4ed4-8bee-d4057663e6eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using transformers version: 4.56.1\n",
            "Using torch version: 2.8.0+cu126\n",
            "Using datasets version: 4.1.1\n",
            "Using accelerate version: 1.10.1\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "try:\n",
        "  import datasets, evaluate, accelerate\n",
        "  import gradio as gr\n",
        "except ModuleNotFoundError:\n",
        "  !pip install -U datasets evaluate accelerate gradio\n",
        "  import datasets, evaluate, accelerate, gradio\n",
        "  import gradio as gr\n",
        "\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "print(f\"Using transformers version: {transformers.__version__}\")\n",
        "print(f\"Using torch version: {torch.__version__}\")\n",
        "print(f\"Using datasets version: {datasets.__version__}\")\n",
        "print(f\"Using accelerate version: {accelerate.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muHBFEsW8Wfd"
      },
      "source": [
        "## Getting a dataset\n",
        "\n",
        "Building food / not food text classification model: need food / not food text dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNQd1b5I5HLl",
        "outputId": "3b615855-2769-4b85-c67b-862f2ab7cfb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 250\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 199,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(path=\"mrdbourke/learn_hf_food_not_food_image_captions\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlYC_cMz-Qtd",
        "outputId": "c5cb9ac5-1a2a-4d8b-e64c-e316910fc9c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': ['text', 'label']}"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# what features are there?\n",
        "dataset.column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRbmcoQv-biS",
        "outputId": "ad109b0e-2ff8-445e-ba28-bbbbe2301fa2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 250\n",
              "})"
            ]
          },
          "execution_count": 201,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Access the training split\n",
        "dataset[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luj7G5SS-jp6",
        "outputId": "b4ea8bf3-c872-46d4-bbbb-b66508c2befd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',\n",
              " 'label': 'food'}"
            ]
          },
          "execution_count": 202,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTytjJfP-zoC"
      },
      "source": [
        "### Inspect random samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI5jzN7L-n38",
        "outputId": "bb4a84ff-b806-47f2-f698-a3dca012d240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6, 189, 70, 62, 57]\n",
            "[INFO] Random samples from dataset:\n",
            "\n",
            "Text: Pair of reading glasses left open on a book | Label: not_food\n",
            "Text: Set of board games stacked on a shelf | Label: not_food\n",
            "Text: Two handfuls of bananas in a fruit bowl with grapes on the side, the fruit bowl is blue | Label: food\n",
            "Text: Computer desk with laptop and computer monitor on it with a mousepad and keyboard | Label: not_food\n",
            "Text: Vegetarian sushi roll with avocado and pickled radish filling. | Label: food\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "random_indexes = random.sample(range(len(dataset[\"train\"])), 5)\n",
        "print(random_indexes)\n",
        "\n",
        "random_samples = dataset[\"train\"][random_indexes]\n",
        "\n",
        "print(f\"[INFO] Random samples from dataset:\\n\")\n",
        "for text, label in zip(random_samples[\"text\"], random_samples[\"label\"]):\n",
        "  print(f\"Text: {text} | Label: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VRiai80-_HL",
        "outputId": "9b084ad8-74b6-4a45-eca7-e5b017217f67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['food', 'not_food']"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get unique label values\n",
        "dataset[\"train\"].unique(\"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2Aa42QJATR7",
        "outputId": "c362a27b-d0f2-48ff-c06d-08922751c836"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'food': 125, 'not_food': 125})"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the count of each label\n",
        "from collections import Counter\n",
        "\n",
        "Counter(dataset[\"train\"][\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "22-O-z7pAtLC",
        "outputId": "e8c4c884-ddab-4b7d-d28f-580009a98bff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"food_not_food_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"A slice of pizza with a generous amount of shredded parmesan cheese on top\",\n          \"Pair of reading glasses left open on a book\",\n          \"A steaming bowl of fiery chicken curry, infused with a blend of aromatic spices and topped with fresh cilantro leaves.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"not_food\",\n          \"food\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-dc8c0ab0-4b74-4b45-aebc-3f4f9e3b457b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>A slice of pizza with a generous amount of shr...</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Pair of reading glasses left open on a book</td>\n",
              "      <td>not_food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Telescope positioned on a balcony</td>\n",
              "      <td>not_food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>A close-up of a family playing a board game wi...</td>\n",
              "      <td>not_food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>Rich and spicy lamb rogan josh with yogurt gar...</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>A steaming bowl of fiery chicken curry, infuse...</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>Pizza with a stuffed crust, oozing with cheese</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc8c0ab0-4b74-4b45-aebc-3f4f9e3b457b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc8c0ab0-4b74-4b45-aebc-3f4f9e3b457b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc8c0ab0-4b74-4b45-aebc-3f4f9e3b457b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2ad148c5-c156-4a23-8713-2cfff6ef3763\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ad148c5-c156-4a23-8713-2cfff6ef3763')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2ad148c5-c156-4a23-8713-2cfff6ef3763 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                  text     label\n",
              "142  A slice of pizza with a generous amount of shr...      food\n",
              "6          Pair of reading glasses left open on a book  not_food\n",
              "97                   Telescope positioned on a balcony  not_food\n",
              "60   A close-up of a family playing a board game wi...  not_food\n",
              "112  Rich and spicy lamb rogan josh with yogurt gar...      food\n",
              "181  A steaming bowl of fiery chicken curry, infuse...      food\n",
              "197     Pizza with a stuffed crust, oozing with cheese      food"
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Turn our dataset into a dataframe and get a random sample\n",
        "food_not_food_df = pd.DataFrame(dataset[\"train\"])\n",
        "food_not_food_df.sample(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "hpFzb95gA_x9",
        "outputId": "244f6880-ea00-4dab-8424-28224c7fdd81"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>food</th>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>not_food</th>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "food        125\n",
              "not_food    125\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 207,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "food_not_food_df[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GBV-aaRBRtZ"
      },
      "source": [
        "## Preparing data for text classification\n",
        "\n",
        "Weâ€™ve got our data ready but there are a few steps weâ€™ll need to take before we can model it.\n",
        "\n",
        "The main two being:\n",
        "\n",
        "1. **Tokenization** - turning our text into a numerical representation (machines prefer numbers rather than words), for example, {\"a\": 0, \"b\": 1, \"c\": 2...}.\n",
        "2. **Creating a train/test split** - right now our data is in a training split only but weâ€™ll create a test set to evaluate our modelâ€™s performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_Uu0SH9BGfK",
        "outputId": "5e0c4d0b-8095-442a-9149-5fba91717926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'not_food', 1: 'food'}\n",
            "{'not_food': 0, 'food': 1}\n"
          ]
        }
      ],
      "source": [
        "# Create a mapping for labels to numeric value\n",
        "id2label = {0: \"not_food\", 1: \"food\"}\n",
        "label2id = {\"not_food\": 0, \"food\": 1}\n",
        "\n",
        "print(id2label)\n",
        "print(label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOVtqdFbCQwH",
        "outputId": "b8b21dfd-aaf8-4663-e80c-0ff5f28d7041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'not_food', 1: 'food'}\n",
            "{'not_food': 0, 'food': 1}\n"
          ]
        }
      ],
      "source": [
        "# Create mappings programmatically from dataset\n",
        "id2label = {idx: label for idx, label in enumerate(dataset[\"train\"].unique(\"label\")[::-1])}\n",
        "label2id = {label: idx for idx, label in id2label.items()}\n",
        "print(id2label)\n",
        "print(label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp7kkGBuCo3P",
        "outputId": "7e576ad1-e6fa-4da6-b06b-da7bd72d92d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 not_food\n",
            "1 food\n"
          ]
        }
      ],
      "source": [
        "id2label = {}\n",
        "for idx, label in enumerate(dataset[\"train\"].unique(\"label\")[::-1]):\n",
        "  print(idx, label)\n",
        "  id2label[idx] = label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auK2GP4bD3Id",
        "outputId": "64332ec0-f22c-426e-d590-790721cc13e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'This is a sentence about my favorite food: pizza', 'label': 1}"
            ]
          },
          "execution_count": 211,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Turn labels into 0 or 1\n",
        "def map_labels_to_number(example):\n",
        "  example[\"label\"] = label2id[example[\"label\"]]\n",
        "  return example\n",
        "\n",
        "example_sample = {\"text\": \"This is a sentence about my favorite food: pizza\", \"label\": \"food\"}\n",
        "\n",
        "# Test our function\n",
        "map_labels_to_number(example_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IS4z6zxFA_N",
        "outputId": "68a97a0d-1198-4a0a-e817-a8e342a7958c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': ['Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',\n",
              "  'Set of books stacked on a desk',\n",
              "  'Watching TV together, a family has their dog stretched out on the floor',\n",
              "  'Wooden dresser with a mirror reflecting the room',\n",
              "  'Lawn mower stored in a shed'],\n",
              " 'label': [1, 0, 0, 0, 0]}"
            ]
          },
          "execution_count": 212,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Map our dataset labels to numbers (the whole dataset)\n",
        "# We do this with dataset.map()\n",
        "dataset = dataset[\"train\"].map(map_labels_to_number)\n",
        "dataset[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qThpS8GKGB6f",
        "outputId": "1ce473d7-9f9e-49e3-c719-5bbfbf711cdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': ['Set of oven mitts hanging on a hook',\n",
              "  'Set of cookie cutters collected in a jar',\n",
              "  'Pizza with a dessert twist, featuring a sweet Nutella base and fresh strawberries on top',\n",
              "  'Set of binoculars placed on a table',\n",
              "  'Two handfuls of bananas in a fruit bowl with grapes on the side, the fruit bowl is blue'],\n",
              " 'label': [0, 0, 1, 0, 1]}"
            ]
          },
          "execution_count": 213,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Shuffle data and look at 5 more random samples\n",
        "dataset.shuffle()[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7ffPJo0GjtL"
      },
      "source": [
        "## Split the dataset into training and test sets\n",
        "\n",
        "* Train set - the model will learn patterns on this dataset.\n",
        "\n",
        "* Validation set (optional) - we can tune our model's hyperparameters on this set (because we are using a small dataset we can leave this out and just have a train and a test set).\n",
        "\n",
        "* Test set - the model will evaluate patterns on this dataset.\n",
        "\n",
        "We can split our dataset using `datasets.Dataset.train_test_split()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DD4MX25Gdek",
        "outputId": "83d5a57a-d900-484c-d6da-b7579342f288"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 200\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 214,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split our dataset in train/test/split\n",
        "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIeA4BG0Ijh7",
        "outputId": "86ee3f08-3385-4888-c90e-570d869cdb43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'Decadent butter chicken curry, featuring tender chicken in a velvety sauce made with butter and tomatoes, served with warm naan bread.',\n",
              " 'label': 1}"
            ]
          },
          "execution_count": 215,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_idx_train = random.randint(0, len(dataset[\"train\"]))\n",
        "random_sample_train = dataset[\"train\"][random_idx_train]\n",
        "random_sample_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7OiG5oiJS_L",
        "outputId": "3961eaba-090f-4c92-df5b-9c75101008cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'Pizza with a dessert twist, featuring a sweet Nutella base and fresh strawberries on top',\n",
              " 'label': 1}"
            ]
          },
          "execution_count": 216,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_idx_test = random.randint(0, len(dataset[\"test\"]))\n",
        "random_sample_test = dataset[\"test\"][random_idx_test]\n",
        "random_sample_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMHAOk7KJxmH"
      },
      "source": [
        "### Tokenizing text data (turning text into numbers)\n",
        "\n",
        "The premise of tokenization is to turn words into numbers.\n",
        "\n",
        "For example: \"I love ice cream\" -> [40, 150, 789, 500]\n",
        "\n",
        "_\n",
        "\n",
        "The transformers library has in-built support for HuggingFace `Tokenizers`.\n",
        "\n",
        "And the class `transformers.AutoTokenizer` helps pair a model to a tokenizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0M5w8bfJlE7",
        "outputId": "0fafbed8-05d3-4e28-ff9d-ce6010ab0a7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}\n",
              ")"
            ]
          },
          "execution_count": 217,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=\"distilbert/distilbert-base-uncased\",\n",
        "                                          use_fast=True)\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tal3J3bWLl7b",
        "outputId": "70eee8d5-1851-4b63-eaea-7d6c9090b19e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1045, 2293, 10733, 102], 'attention_mask': [1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 218,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test out the tokenizer\n",
        "tokenizer(\"I love pizza\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfoRyaWtMR7m"
      },
      "source": [
        "* `input_ids` = our text turned into numbers. [CLS, I, love, pizza, SEP]\n",
        "* `attention_mask` = whether or not to pay attention to certain tokens (1 = yes pay attention, 0 = no, don't pay attention)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DvzaS4HMJGq",
        "outputId": "d6483ac3-c249-4c42-939c-68fa4469013b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1045, 2293, 10733, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 219,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(\"I love pizza!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ot986WTNvoz",
        "outputId": "56e2ab33-cbae-4315-a369-9718843468b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO]: Number of items in our tokenizer vocab: 30522\n",
            "[INFO] Max tokenizer input sequence length: 512\n"
          ]
        }
      ],
      "source": [
        "# Get the length of our tokenizer vocab\n",
        "length_of_tokenizer_vocab = len(tokenizer.vocab)\n",
        "print(f\"[INFO]: Number of items in our tokenizer vocab: {length_of_tokenizer_vocab}\")\n",
        "\n",
        "# Get the maximum sequence length the tokenizer can handle\n",
        "max_tokenizer_input_sequence_length = tokenizer.model_max_length\n",
        "print(f\"[INFO] Max tokenizer input sequence length: {max_tokenizer_input_sequence_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIWbvW4YOjCj",
        "outputId": "0919f70a-9669-41fb-83b9-b493c592f19b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7592"
            ]
          },
          "execution_count": 221,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Does \"Elizabeth\" occur in the vocab?\n",
        "tokenizer.vocab[\"hello\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7rmPWAOPL7a",
        "outputId": "d9357a4d-1a2d-402e-8447-ad2315f51178"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 3870, 102], 'attention_mask': [1, 1, 1]}"
            ]
          },
          "execution_count": 222,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(\"Elizabeth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrtDlHx-PkJ7",
        "outputId": "4c5a92a4-7f63-43e8-b319-d14e7d078e3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[CLS]', 'elizabeth', '[SEP]']"
            ]
          },
          "execution_count": 223,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens(tokenizer(\"Elizabeth\").input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILhXEIFrPuAj",
        "outputId": "c734c632-d9dd-4831-f99c-c94feea27607"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[CLS]', '[UNK]', '[SEP]']"
            ]
          },
          "execution_count": 224,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Try to tokenize an emoji\n",
        "tokenizer.convert_ids_to_tokens(tokenizer(\"ðŸ˜Š\").input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IlER42VQGOC",
        "outputId": "8018b3b2-fc88-44aa-c89e-c6796cd8e9a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('!', 999), ('\"', 1000), ('#', 1001), ('##!', 29612), ('##\"', 29613)]"
            ]
          },
          "execution_count": 225,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the first 5 items in the tokenizer vocab\n",
        "sorted(tokenizer.vocab.items())[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cIvnF8lQVD6",
        "outputId": "63178145-4b73-49f2-9480-059dc6e24a20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('##pm', 9737),\n",
              " ('persona', 16115),\n",
              " ('rhythm', 6348),\n",
              " ('winfield', 24739),\n",
              " ('internship', 22676)]"
            ]
          },
          "execution_count": 226,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "random.sample(sorted(tokenizer.vocab.items()), k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xEgQqGDQ5xW"
      },
      "source": [
        "### Making a preprocessing function to tokenize text.\n",
        "\n",
        "We want to make it easy to go from sample to tokenized_sample.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMla2VBIQhYD"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(examples):\n",
        "  \"\"\"\n",
        "  Tokenize given example text and return the tokenized text.\n",
        "  \"\"\"\n",
        "  return tokenizer(examples[\"text\"],\n",
        "                   padding=True,\n",
        "                   truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPM7x_Z3Rkqz",
        "outputId": "7b4b02c5-a44b-4b8b-e2be-8546bac570cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1045, 2293, 10733, 102], 'attention_mask': [1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 228,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_sample_2 = {\"text\": \"I love pizza\", \"label\": 1}\n",
        "\n",
        "# Test the function\n",
        "tokenize_text(example_sample_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3Kvh-gkSX4r",
        "outputId": "81b97f1e-1d12-49fe-eed4-6b1ef319e2fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13000"
            ]
          },
          "execution_count": 229,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "long_text = \"I love pizza \" * 1000\n",
        "len(long_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZkqXY43SiFz",
        "outputId": "1ca0a145-75c1-4eaf-b479-4cdf1229fa46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "execution_count": 230,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_long_text = tokenize_text({\"text\": long_text, \"label\": 1})\n",
        "len(tokenized_long_text[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuOSxXWLS_yj",
        "outputId": "28ec0337-0b67-4e5d-9e8a-fd70c5376428"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 200\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 50\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 231,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Map our tokenized text function to the dataset\n",
        "tokenized_dataset = dataset.map(function=tokenize_text,\n",
        "                                batched=True,\n",
        "                                batch_size=1000)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QelHwiY2TaL6",
        "outputId": "e67f9693-6a4d-4f83-9ca6-c33dca224896"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Key: text\n",
            "Train Sample: Set of headphones placed on a desk\n",
            "Test Sample: A slice of pepperoni pizza with a layer of melted cheese\n",
            "\n",
            "[INFO] Key: label\n",
            "Train Sample: 0\n",
            "Test Sample: 1\n",
            "\n",
            "[INFO] Key: input_ids\n",
            "Train Sample: [101, 2275, 1997, 2132, 19093, 2872, 2006, 1037, 4624, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Test Sample: [101, 1037, 14704, 1997, 11565, 10698, 10733, 2007, 1037, 6741, 1997, 12501, 8808, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "[INFO] Key: attention_mask\n",
            "Train Sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Test Sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get two samples from the tokenized datasets\n",
        "train_tokenized_sample = tokenized_dataset[\"train\"][0]\n",
        "test_tokenized_sample = tokenized_dataset[\"test\"][0]\n",
        "\n",
        "for key in train_tokenized_sample.keys():\n",
        "  print(f\"[INFO] Key: {key}\")\n",
        "  print(f\"Train Sample: {train_tokenized_sample[key]}\")\n",
        "  print(f\"Test Sample: {test_tokenized_sample[key]}\")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs9l8ZiaVzTw"
      },
      "source": [
        "### Tokenization takeaways\n",
        "\n",
        "1. Tokenizers = turn data into numbers (e.g. text -> map to number)\n",
        "2. Many models are out there and have different tokenizers, HuggingFace's `Auto` (e.g. `AutoTokenizer`, `AutoProcessor`, `AutoModel`, etc help to match tokenizers to models)\n",
        "3. Tokenizers can happen in parallel using `map` and `batched` functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhAp10zNWzq-"
      },
      "source": [
        "## Setting up an evaluation metric.\n",
        "\n",
        "We want to use the evaluation metric to get a numerical idea of how our model is performing.\n",
        "\n",
        "Some common evaluation metrics for classification are:\n",
        "* Accuracy (how many examples out of 100 did you get correct?)\n",
        "* Precision\n",
        "* Recall\n",
        "* F1 Score\n",
        "\n",
        "Evaluation metric is important because some projects may have an evaluation threshold to fulfill.\n",
        "\n",
        "\n",
        "E.g. May require 98%+ test accuracy to be commercially viable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPanXWVRUjuy"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "from typing import Tuple\n",
        "\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_accuracy(predictions_and_labels: Tuple[np.array, np.array]):\n",
        "  \"\"\"\n",
        "  Computes the accuracy of a model by comparing the predictions and labels.\n",
        "  \"\"\"\n",
        "  predictions, labels = predictions_and_labels\n",
        "\n",
        "  return accuracy_metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAb7ZZVta9Ls",
        "outputId": "dd2eb4b4-61a6-4ca1-ae20-e6bafe846c71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy when all predictions are correct: {'accuracy': 1.0}\n",
            "Accuracy when one prediction is incorrect: {'accuracy': 0.9}\n"
          ]
        }
      ],
      "source": [
        "# Example predictions and accuracy score\n",
        "example_preds_all_correct = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "example_preds_one_incorrect = np.array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
        "example_labels = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "\n",
        "# Test the function\n",
        "print(f\"Accuracy when all predictions are correct: {compute_accuracy((example_preds_all_correct, example_labels))}\")\n",
        "print(f\"Accuracy when one prediction is incorrect: {compute_accuracy((example_preds_one_incorrect, example_labels))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tmXQRNrb3Vt"
      },
      "source": [
        "## Setting up a model for training.\n",
        "\n",
        "* We're going to be using transfer learning.\n",
        "* Transfer learning is a powerful technique, unique to deep learning models, that enables us to use the patterns one model has learned on another problem for our own problem.\n",
        "\n",
        "\n",
        "Workflow for training:\n",
        "1. Create and preprocess data âœ…\n",
        "2. Define the model we'd like to use for our problem (in our case it will be the `distilbert/distilbert-base-uncased` model found here:   https://huggingface.co/distilbert/distilbert-base-uncased)\n",
        "3. Define training arguments for training our model using `transformers.TrainingArguments`\n",
        "4. Pass `TrainingArguments` to an instance of `transformers.Trainer`\n",
        "5. Train the model by calling `Trainer.train()`\n",
        "6. Save the model (to our local machine or to the HuggingFace Hub)\n",
        "7. Evaluate the trained model by making and inspecting predictions on the test data (and our own custom data)\n",
        "8. Turn the model into a shareable demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i19af1GAbvWK",
        "outputId": "c46d9ef6-09b5-45fc-e863-9ece8b3ca7fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"distilbert/distilbert-base-uncased\",\n",
        "    num_labels=2,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqrU_lIyzur0",
        "outputId": "0090ed01-93be-4eed-93e1-a0bf6e607060"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 236,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTBBFRgY0bR5"
      },
      "source": [
        "Our model is comprised of the following parts:\n",
        "\n",
        "1. `Embeddings` - embeddings are a form of learned representation of tokens. So if tokens are a direct mapping from token to number, embeddings are a learned vector representation.\n",
        "2. `Transformer` - our model architecture backbone, this has discovered patterns/relationships in the embeddings.\n",
        "3. `Classifier` - we need to customize this layer to suit our problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsC7jOCQ1aId"
      },
      "source": [
        "### Counting the parameters of our model.\n",
        "\n",
        "Weights/parameters = small numeric opportunities for a model to learn patterns in data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XKlN72t0TVb",
        "outputId": "3a7120bb-b5f9-4159-b15a-5f304e9fcfab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'trainable_parameters': 66955010, 'total_parameters': 66955010}"
            ]
          },
          "execution_count": 237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def count_params(model):\n",
        "  \"\"\"\n",
        "  Count the parameters of a PyTorch model.\n",
        "  \"\"\"\n",
        "  trainable_parameters = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
        "  total_parameters = sum(param.numel() for param in model.parameters())\n",
        "\n",
        "  return {\"trainable_parameters\": trainable_parameters,\n",
        "          \"total_parameters\": total_parameters}\n",
        "\n",
        "count_params(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb0BsbXD4Q6M"
      },
      "source": [
        "Looks like our model has 67M parameters and **all** of them are trainable.\n",
        "\n",
        "* Generally, the more parameters a model has, the more capacity it has to learn.\n",
        "* For the best possible performance, more parameters is better (generally).\n",
        "  - However, more parameters requires more compute and time.\n",
        "  - A smaller model with specific data can perfrom just as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mU5FKcM52Sj"
      },
      "source": [
        "### Create a folder or directory for saving models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5FSSPZQ3oJU",
        "outputId": "fc5053fd-88fb-4e9a-a796-ddac92741724"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PosixPath('models/food_not_food_distilbert-base-uncased_text_classification_model')"
            ]
          },
          "execution_count": 238,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create model output directory\n",
        "from pathlib import Path\n",
        "\n",
        "# Create models dir\n",
        "models_dir = Path(\"models\")\n",
        "models_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Create model save name\n",
        "model_save_name = \"food_not_food_distilbert-base-uncased_text_classification_model\"\n",
        "\n",
        "# Create model save path\n",
        "model_save_dir = Path(models_dir, model_save_name)\n",
        "\n",
        "model_save_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZD9WwtP63JV"
      },
      "source": [
        "### Setting up hyperparameters with TrainingArguments\n",
        "\n",
        "Workflow for training:\n",
        "1. âœ… Create and preprocess data\n",
        "2. âœ… Define the model we'd like to use for our problem (in our case it will be the `distilbert/distilbert-base-uncased` model found here:   https://huggingface.co/distilbert/distilbert-base-uncased)\n",
        "3. Define training arguments for training our model using `transformers.TrainingArguments`\n",
        "\n",
        "   - These are also known as \"hyperparameters\" = settings on your model that you can adjust\n",
        "   - Parameters = weightes/patterns in the model that get updated automatically\n",
        "\n",
        "4. Pass `TrainingArguments` to an instance of `transformers.Trainer`\n",
        "5. Train the model by calling `Trainer.train()`\n",
        "6. Save the model (to our local machine or to the HuggingFace Hub)\n",
        "7. Evaluate the trained model by making and inspecting predictions on the test data (and our own custom data)\n",
        "8. Turn the model into a shareable demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEJ1qpg66sgt",
        "outputId": "5dc64b72-d11d-4c58-eb1a-eb56197276b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Saving model checkpoints to: models/food_not_food_distilbert-base-uncased_text_classification_model\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "print(f\"[INFO] Saving model checkpoints to: {model_save_dir}\")\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_save_dir,\n",
        "    learning_rate=0.0001,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=10,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=3,\n",
        "    use_cpu=False,\n",
        "    seed=42,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        "    hub_private_repo=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sx_2J1oY_bh7",
        "outputId": "8390aa3d-ee43-49b0-b38b-e6d6f29e03f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TrainingArguments(\n",
              "_n_gpu=1,\n",
              "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
              "adafactor=False,\n",
              "adam_beta1=0.9,\n",
              "adam_beta2=0.999,\n",
              "adam_epsilon=1e-08,\n",
              "auto_find_batch_size=False,\n",
              "average_tokens_across_devices=False,\n",
              "batch_eval_metrics=False,\n",
              "bf16=False,\n",
              "bf16_full_eval=False,\n",
              "data_seed=None,\n",
              "dataloader_drop_last=False,\n",
              "dataloader_num_workers=0,\n",
              "dataloader_persistent_workers=False,\n",
              "dataloader_pin_memory=True,\n",
              "dataloader_prefetch_factor=None,\n",
              "ddp_backend=None,\n",
              "ddp_broadcast_buffers=None,\n",
              "ddp_bucket_cap_mb=None,\n",
              "ddp_find_unused_parameters=None,\n",
              "ddp_timeout=1800,\n",
              "debug=[],\n",
              "deepspeed=None,\n",
              "disable_tqdm=False,\n",
              "do_eval=True,\n",
              "do_predict=False,\n",
              "do_train=False,\n",
              "eval_accumulation_steps=None,\n",
              "eval_delay=0,\n",
              "eval_do_concat_batches=True,\n",
              "eval_on_start=False,\n",
              "eval_steps=None,\n",
              "eval_strategy=IntervalStrategy.EPOCH,\n",
              "eval_use_gather_object=False,\n",
              "fp16=False,\n",
              "fp16_backend=auto,\n",
              "fp16_full_eval=False,\n",
              "fp16_opt_level=O1,\n",
              "fsdp=[],\n",
              "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
              "fsdp_min_num_params=0,\n",
              "fsdp_transformer_layer_cls_to_wrap=None,\n",
              "full_determinism=False,\n",
              "gradient_accumulation_steps=1,\n",
              "gradient_checkpointing=False,\n",
              "gradient_checkpointing_kwargs=None,\n",
              "greater_is_better=False,\n",
              "group_by_length=False,\n",
              "half_precision_backend=auto,\n",
              "hub_always_push=False,\n",
              "hub_model_id=None,\n",
              "hub_private_repo=False,\n",
              "hub_revision=None,\n",
              "hub_strategy=HubStrategy.EVERY_SAVE,\n",
              "hub_token=<HUB_TOKEN>,\n",
              "ignore_data_skip=False,\n",
              "include_for_metrics=[],\n",
              "include_inputs_for_metrics=False,\n",
              "include_num_input_tokens_seen=False,\n",
              "include_tokens_per_second=False,\n",
              "jit_mode_eval=False,\n",
              "label_names=None,\n",
              "label_smoothing_factor=0.0,\n",
              "learning_rate=0.0001,\n",
              "length_column_name=length,\n",
              "liger_kernel_config=None,\n",
              "load_best_model_at_end=True,\n",
              "local_rank=0,\n",
              "log_level=passive,\n",
              "log_level_replica=warning,\n",
              "log_on_each_node=True,\n",
              "logging_dir=models/food_not_food_distilbert-base-uncased_text_classification_model/runs/Sep29_22-27-35_7163b1f2f128,\n",
              "logging_first_step=False,\n",
              "logging_nan_inf_filter=True,\n",
              "logging_steps=500,\n",
              "logging_strategy=IntervalStrategy.EPOCH,\n",
              "lr_scheduler_kwargs={},\n",
              "lr_scheduler_type=SchedulerType.LINEAR,\n",
              "max_grad_norm=1.0,\n",
              "max_steps=-1,\n",
              "metric_for_best_model=loss,\n",
              "mp_parameters=,\n",
              "neftune_noise_alpha=None,\n",
              "no_cuda=False,\n",
              "num_train_epochs=10,\n",
              "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
              "optim_args=None,\n",
              "optim_target_modules=None,\n",
              "output_dir=models/food_not_food_distilbert-base-uncased_text_classification_model,\n",
              "overwrite_output_dir=False,\n",
              "parallelism_config=None,\n",
              "past_index=-1,\n",
              "per_device_eval_batch_size=32,\n",
              "per_device_train_batch_size=32,\n",
              "prediction_loss_only=False,\n",
              "push_to_hub=False,\n",
              "push_to_hub_model_id=None,\n",
              "push_to_hub_organization=None,\n",
              "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
              "ray_scope=last,\n",
              "remove_unused_columns=True,\n",
              "report_to=[],\n",
              "restore_callback_states_from_checkpoint=False,\n",
              "resume_from_checkpoint=None,\n",
              "run_name=None,\n",
              "save_on_each_node=False,\n",
              "save_only_model=False,\n",
              "save_safetensors=True,\n",
              "save_steps=500,\n",
              "save_strategy=SaveStrategy.EPOCH,\n",
              "save_total_limit=3,\n",
              "seed=42,\n",
              "skip_memory_metrics=True,\n",
              "tf32=None,\n",
              "torch_compile=False,\n",
              "torch_compile_backend=None,\n",
              "torch_compile_mode=None,\n",
              "torch_empty_cache_steps=None,\n",
              "torchdynamo=None,\n",
              "tpu_metrics_debug=False,\n",
              "tpu_num_cores=None,\n",
              "use_cpu=False,\n",
              "use_ipex=False,\n",
              "use_legacy_prediction_loop=False,\n",
              "use_liger_kernel=False,\n",
              "use_mps_device=False,\n",
              "warmup_ratio=0.0,\n",
              "warmup_steps=0,\n",
              "weight_decay=0.0,\n",
              ")"
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jftq6FnxjbJC"
      },
      "source": [
        "### Setting up an instance of Trainer\n",
        "\n",
        "Workflow for training:\n",
        "1. âœ… Create and preprocess data\n",
        "2. âœ… Define the model we'd like to use for our problem (in our case it will be the `distilbert/distilbert-base-uncased` model found here:   https://huggingface.co/distilbert/distilbert-base-uncased)\n",
        "3. âœ… Define training arguments for training our model using `transformers.TrainingArguments`\n",
        "\n",
        "   - These are also known as \"hyperparameters\" = settings on your model that you can adjust\n",
        "   - Parameters = weightes/patterns in the model that get updated automatically\n",
        "\n",
        "4. Pass `TrainingArguments` to an instance of `transformers.Trainer`\n",
        "5. Train the model by calling `Trainer.train()`\n",
        "6. Save the model (to our local machine or to the HuggingFace Hub)\n",
        "7. Evaluate the trained model by making and inspecting predictions on the test data (and our own custom data)\n",
        "8. Turn the model into a shareable demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sT4gUmimnJV"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "from typing import Tuple\n",
        "\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_accuracy(predictions_and_labels: Tuple[np.array, np.array]):\n",
        "  \"\"\"\n",
        "  Computes the accuracy of a model by comparing the predictions and labels.\n",
        "  \"\"\"\n",
        "  predictions, labels = predictions_and_labels\n",
        "\n",
        "  if len(predictions.shape) >= 2:\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "  return accuracy_metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxRBeIRg_dSj",
        "outputId": "875d2707-f053-4ddb-94ae-d0c612748f93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-247060917.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<transformers.trainer.Trainer at 0x7ad7c39229f0>"
            ]
          },
          "execution_count": 242,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "# Setup Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_accuracy\n",
        ")\n",
        "\n",
        "trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTEKn-kOlMq3"
      },
      "source": [
        "### Train the model by calling `Trainer.train`\n",
        "\n",
        "Workflow for training:\n",
        "1. âœ… Create and preprocess data\n",
        "2. âœ… Define the model we'd like to use for our problem (in our case it will be the `distilbert/distilbert-base-uncased` model found here:   https://huggingface.co/distilbert/distilbert-base-uncased)\n",
        "3. âœ… Define training arguments for training our model using `transformers.TrainingArguments`\n",
        "\n",
        "   - These are also known as \"hyperparameters\" = settings on your model that you can adjust\n",
        "   - Parameters = weightes/patterns in the model that get updated automatically\n",
        "\n",
        "4. âœ… Pass `TrainingArguments` to an instance of `transformers.Trainer`\n",
        "5. Train the model by calling `Trainer.train()`\n",
        "6. Save the model (to our local machine or to the HuggingFace Hub)\n",
        "7. Evaluate the trained model by making and inspecting predictions on the test data (and our own custom data)\n",
        "8. Turn the model into a shareable demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSLAAzBcl0-E",
        "outputId": "4a672f04-0ee2-4bf1-c200-cf4f4f366e55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "execution_count": 243,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_predictions = np.array([[-1.5652031, 1.4852538 ]])\n",
        "input_references = np.array([0])\n",
        "\n",
        "# Need to get the maximum value from the model output (the index) as this is the most likely label according to the model\n",
        "if len(input_predictions.shape) >= 2:\n",
        "    input_predictions = np.argmax(input_predictions, axis=1)\n",
        "\n",
        "input_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1-ZmH8lmozw",
        "outputId": "8cf26837-3cb8-437c-a63d-f9e8161883ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.0}"
            ]
          },
          "execution_count": 244,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_accuracy(predictions_and_labels=(input_predictions, input_references))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "PNy9svAalLWF",
        "outputId": "76d2855b-92e4-4d38-cc02-68c58e351c84"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70/70 04:00, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.338800</td>\n",
              "      <td>0.041322</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.019300</td>\n",
              "      <td>0.005754</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.002047</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>0.001152</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000819</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.000670</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.000593</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000550</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000528</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000520</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25DzkbEmplmK",
        "outputId": "195bd3cd-5741-45ed-ce44-0d98654c1a46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_runtime : 240.2006\n",
            "train_samples_per_second : 8.326\n",
            "train_steps_per_second : 0.291\n",
            "total_flos : 18110777160000.0\n",
            "train_loss : 0.03679406267058637\n",
            "epoch : 10.0\n"
          ]
        }
      ],
      "source": [
        "# Inspect training metrics\n",
        "for key, value in results.metrics.items():\n",
        "  print(f\"{key} : {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYMyeh9op7US"
      },
      "source": [
        "### Save the model for later use\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IciQih0bqDK4",
        "outputId": "b8e77025-af92-4332-bf8d-0708e47fb913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model to models/food_not_food_distilbert-base-uncased_text_classification_model\n"
          ]
        }
      ],
      "source": [
        "# Save model\n",
        "print(f\"Saving model to {model_save_dir}\")\n",
        "trainer.save_model(output_dir=model_save_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AioHw6rEqaW9"
      },
      "source": [
        "### Inspect the model training metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hopNmTRrn3B",
        "outputId": "4dae8bfc-6125-4d98-fddf-01ddd715ea73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'loss': 0.3388,\n",
              "  'grad_norm': 0.9611281752586365,\n",
              "  'learning_rate': 9.142857142857143e-05,\n",
              "  'epoch': 1.0,\n",
              "  'step': 7},\n",
              " {'eval_loss': 0.04132193699479103,\n",
              "  'eval_accuracy': 1.0,\n",
              "  'eval_runtime': 0.0532,\n",
              "  'eval_samples_per_second': 940.111,\n",
              "  'eval_steps_per_second': 37.604,\n",
              "  'epoch': 1.0,\n",
              "  'step': 7},\n",
              " {'loss': 0.0193,\n",
              "  'grad_norm': 0.09880883246660233,\n",
              "  'learning_rate': 8.142857142857143e-05,\n",
              "  'epoch': 2.0,\n",
              "  'step': 14}]"
            ]
          },
          "execution_count": 248,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get training history\n",
        "trainer_history_all = trainer.state.log_history\n",
        "trainer_history_metrics = trainer_history_all[:-1]\n",
        "trainer_history_training_time = trainer_history_all[-1]\n",
        "\n",
        "# View the first 3\n",
        "trainer_history_metrics[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AefwKbWCr9Oi",
        "outputId": "09d3e2a4-637f-45ba-df5c-bdca98c97dec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First two in training set:\n",
            "[{'epoch': 1.0,\n",
            "  'grad_norm': 0.9611281752586365,\n",
            "  'learning_rate': 9.142857142857143e-05,\n",
            "  'loss': 0.3388,\n",
            "  'step': 7},\n",
            " {'epoch': 2.0,\n",
            "  'grad_norm': 0.09880883246660233,\n",
            "  'learning_rate': 8.142857142857143e-05,\n",
            "  'loss': 0.0193,\n",
            "  'step': 14}]\n",
            "\n",
            "First two in eval epochs:\n",
            "[{'epoch': 1.0,\n",
            "  'eval_accuracy': 1.0,\n",
            "  'eval_loss': 0.04132193699479103,\n",
            "  'eval_runtime': 0.0532,\n",
            "  'eval_samples_per_second': 940.111,\n",
            "  'eval_steps_per_second': 37.604,\n",
            "  'step': 7},\n",
            " {'epoch': 2.0,\n",
            "  'eval_accuracy': 1.0,\n",
            "  'eval_loss': 0.0057538952678442,\n",
            "  'eval_runtime': 0.0527,\n",
            "  'eval_samples_per_second': 948.577,\n",
            "  'eval_steps_per_second': 37.943,\n",
            "  'step': 14}]\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "\n",
        "# Extract eval and training metrics\n",
        "trainer_history_training_set = []\n",
        "trainer_history_eval_set = []\n",
        "\n",
        "# Loop through our metrics\n",
        "for item in trainer_history_metrics:\n",
        "  item_keys = list(item.keys())\n",
        "  if any(\"eval\" in item for item in item_keys):\n",
        "    trainer_history_eval_set.append(item)\n",
        "  else:\n",
        "    trainer_history_training_set.append(item)\n",
        "\n",
        "# View the first from each\n",
        "print(f\"First two in training set:\")\n",
        "pprint.pprint(trainer_history_training_set[:2])\n",
        "\n",
        "print(f\"\\nFirst two in eval epochs:\")\n",
        "pprint.pprint(trainer_history_eval_set[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH7fs3TBuRjd"
      },
      "source": [
        "### Taking a look at the loss curves\n",
        "\n",
        "Loss curves are a good visualization of your model's performance over time, and ideally will trend downwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VgXYZe37s04y",
        "outputId": "2975fd81-f094-4fad-cc5d-f910a6b4b310"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"trainer_history_train_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10627534259857478,\n        \"min\": 0.0006,\n        \"max\": 0.3388,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.0193,\n          0.0008,\n          0.3388\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"grad_norm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2968096769082408,\n        \"min\": 0.008615965023636818,\n        \"max\": 0.9611281752586365,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.008615965023636818,\n          0.09880883246660233,\n          0.01364204566925764\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.0276503540974917e-05,\n        \"min\": 1.4285714285714286e-06,\n        \"max\": 9.142857142857143e-05,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.1428571428571429e-05,\n          8.142857142857143e-05,\n          4.1428571428571437e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.0276503540974917,\n        \"min\": 1.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9.0,\n          2.0,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": 7,\n        \"max\": 70,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          63,\n          14,\n          42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "trainer_history_train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0fee3e87-f52d-413a-990e-77a9dd19a041\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>grad_norm</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>epoch</th>\n",
              "      <th>step</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.3388</td>\n",
              "      <td>0.961128</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0193</td>\n",
              "      <td>0.098809</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.039035</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>3.0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0017</td>\n",
              "      <td>0.025938</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>4.0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.013744</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>5.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fee3e87-f52d-413a-990e-77a9dd19a041')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0fee3e87-f52d-413a-990e-77a9dd19a041 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0fee3e87-f52d-413a-990e-77a9dd19a041');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bbd05fc0-3d61-42c3-b307-74ede508b03d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bbd05fc0-3d61-42c3-b307-74ede508b03d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bbd05fc0-3d61-42c3-b307-74ede508b03d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     loss  grad_norm  learning_rate  epoch  step\n",
              "0  0.3388   0.961128       0.000091    1.0     7\n",
              "1  0.0193   0.098809       0.000081    2.0    14\n",
              "2  0.0037   0.039035       0.000071    3.0    21\n",
              "3  0.0017   0.025938       0.000061    4.0    28\n",
              "4  0.0010   0.013744       0.000051    5.0    35"
            ]
          },
          "execution_count": 250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a pandas DataFrame for the training and evaluation metrics\n",
        "trainer_history_train_df = pd.DataFrame(trainer_history_training_set)\n",
        "trainer_history_eval_df = pd.DataFrame(trainer_history_eval_set)\n",
        "\n",
        "trainer_history_train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "bcdFd80yvFxJ",
        "outputId": "639d055f-be23-4f69-9512-867bfc7fba8f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the loss curves\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(trainer_history_train_df[\"epoch\"], trainer_history_train_df[\"loss\"], label=\"Training loss\")\n",
        "plt.plot(trainer_history_eval_df[\"epoch\"], trainer_history_eval_df[\"eval_loss\"], label=\"Evaluation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Text Classification Fine-tuning DistilBert Training and Evaluation Loss Over Time\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsFBktCG3lUp"
      },
      "source": [
        "### Pushing our model to the HuggingFace Hub\n",
        "\n",
        "Reasons for doing this:\n",
        "\n",
        "* We can share our model.\n",
        "* Other people can try it out.\n",
        "* We can keep a history of different model versions.\n",
        "\n",
        "To write to HuggingFace:\n",
        "- If on Google Colab: setup \"token\" with \"read and write\" access.\n",
        "- If on local machine: setup `huggingface-cli` (https://huggingface.co/docs/huggingface_hub/en/guides/cli)\n",
        "\n",
        "To save to the HuggingFace Hub we are going to use the `Trainer.push_to_hub` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415,
          "referenced_widgets": [
            "390d02519432438798f43f4d95f567ba",
            "6d46849797ce4cc7887e2b143db8caf0",
            "69cfb5f1483646ac889b66afbbf8ff8f",
            "a4bc3ba863184ebca26af25430c8d9c6",
            "afc82b15b898404d91c0c125e3428cd4",
            "740a644d591142c9832be6ada3bdb250",
            "c553465502b74773852fba0381fcc5a8",
            "c1e3a50915d04220a988a2bae0e2ca92",
            "b205b7132b8b4b0eacf78b987c5e23ac",
            "bd6329e90a014159871c63de4d2b481c",
            "7054b0c65ce14e798f649fd813ce3e2c",
            "edb0f01b470b4893a433e9018bf802e2",
            "fc6473f679754fbe833d2bef4fcec01b",
            "71d8bfd9049046c79c10f5d2afd879dc",
            "167ec58147ee492ca0c0a74eb19fc9b8",
            "ecccfa64004a44779a61c88eb75e3796",
            "4d6b85efcebc425ebb8193c6b99d5a2f"
          ]
        },
        "collapsed": true,
        "id": "jOL-VwDb78Sm",
        "outputId": "7f018719-b51c-4e1a-9883-6514aa4914f1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "390d02519432438798f43f4d95f567ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Log in to Hugging Face from Notebook\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182,
          "referenced_widgets": [
            "ce652a42df504d96afbfcec850140ae0",
            "4cc5562df77b4850903b87aea22d1694",
            "af8c7b1e0ae34fd9a08217353f7f2ed0",
            "6b767f3dcce9405aa3e78508848c6ee2",
            "3d4c4031eaca4906974b5dff45ea662c",
            "d0434f0af51a4b0783d5a12d6937decb",
            "9f2012e934274e81b641856ef68be188",
            "f43171230ab0490593d9f3d25ed5acdc",
            "d3aca0ea25654d7a83cb2adc58165da9",
            "e7cb591d1f4f4a1484b0805fd324e853",
            "46bab6069b6341dc838538160fea1503",
            "7fd0c64b428d4d3b935a39003e81eaa3",
            "e746fbf64bfd401d956659b5a4f8aa7e",
            "5eadcdbbb9fd4f57844fcc446c41d444",
            "c522f7a646b24d01bbc51feb6d454492",
            "c0272b02d31c410caa95a1f35a88bd35",
            "c2ee195276a546b5ad005160c1200661",
            "f58c30806c264794bcfb209a9dd4c5cb",
            "172b8964069843a7bd80ef4494ab2f5e",
            "0a2974fd1e57458a9ad1614241212d54",
            "afe742e8f7a844f89d15460b48795e66",
            "f9179f0ce0e74521921a6433cd89992a",
            "ff6a92738f5c41fb8e7a7fbbd9219c36",
            "24a63ea824004dc4a1e9b5bb6069ddea",
            "7a15f3b15c8c44f3bd9ba8df35d4f65c",
            "5b08013c7cb548548425e21cd976eb6e",
            "976317375137453d94b2204f707ad189",
            "b0674d0938c94387a6c5cf3e5515301e",
            "7dc24ff17bd344438ac35e1399e6be1b",
            "df907c0b471f4a209b4a58586cfb872a",
            "6bcb21d4d91749d8ac12d5532bd8838c",
            "44fea40977c945eea566d556fd3e9164",
            "860952fcb91148eb88f8023fcabae49f",
            "712f2fde0858494a8acc42bf32e1dae4",
            "2258a66b56264e6fb53ad8ac2bf4fe92",
            "e6607766dae6403daa01289bf639f813",
            "e992e17d19c841e08b804cc5789063e5",
            "8495b6b1c0a742c8a92e07955c08f38a",
            "2d8b70867028446ca05e765171a91230",
            "ff7438af95e2449887c62049923d627b",
            "ecc815d6a7ad4e07a64bdfc6d9aef5e1",
            "d9633b15cde0456b84ce7a6955f6cc76",
            "43235ee69ea2426781cfdc0c2762be82",
            "e2db373f79054214bfd6d8bcc1f77bc0"
          ]
        },
        "id": "znsAcd4HwIQ5",
        "outputId": "1ad4ab31-f681-4bbd-96d6-8420b4a33b93"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce652a42df504d96afbfcec850140ae0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7fd0c64b428d4d3b935a39003e81eaa3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff6a92738f5c41fb8e7a7fbbd9219c36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...n_model/model.safetensors:  12%|#2        | 33.1MB /  268MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "712f2fde0858494a8acc42bf32e1dae4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...n_model/training_args.bin:  21%|##        | 1.23kB / 5.84kB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model successfully uploaded to the HuggingFace Hub with URL: https://huggingface.co/LizzChall/food_not_food_distilbert-base-uncased_text_classification_model/tree/main/\n"
          ]
        }
      ],
      "source": [
        "# Save our model to the HuggingFace Hub\n",
        "model_upload_url = trainer.push_to_hub(\n",
        "    commit_message=\"Uploading food not food text classifier model\"\n",
        ")\n",
        "\n",
        "print(f\"Model successfully uploaded to the HuggingFace Hub with URL: {model_upload_url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqC2Bp6c9UEd"
      },
      "source": [
        "### Making and evaluating predictions on the test data.\n",
        "\n",
        "Workflow for training:\n",
        "1. âœ… Create and preprocess data\n",
        "2. âœ… Define the model we'd like to use for our problem (in our case it will be the `distilbert/distilbert-base-uncased` model found here:   https://huggingface.co/distilbert/distilbert-base-uncased)\n",
        "3. âœ… Define training arguments for training our model using `transformers.TrainingArguments`\n",
        "\n",
        "   - These are also known as \"hyperparameters\" = settings on your model that you can adjust\n",
        "   - Parameters = weightes/patterns in the model that get updated automatically\n",
        "\n",
        "4. âœ… Pass `TrainingArguments` to an instance of `transformers.Trainer`\n",
        "5. âœ… Train the model by calling `Trainer.train()`\n",
        "6. âœ… Save the model (to our local machine or to the HuggingFace Hub)\n",
        "7. Evaluate the trained model by making and inspecting predictions on the test data (and our own custom data)\n",
        "8. Turn the model into a shareable demo\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "UxeXqUMd54ox",
        "outputId": "3bf34f4f-370b-4a85-b2d6-9ad0efbf1339"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Prediction metrics on the test data:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'test_loss': 0.0005204931367188692,\n",
              " 'test_accuracy': 1.0,\n",
              " 'test_runtime': 0.0946,\n",
              " 'test_samples_per_second': 528.493,\n",
              " 'test_steps_per_second': 21.14}"
            ]
          },
          "execution_count": 254,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform predictions on the test data\n",
        "predictions_all = trainer.predict(tokenized_dataset[\"test\"])\n",
        "prediction_values = predictions_all.predictions\n",
        "prediction_metrics = predictions_all.metrics\n",
        "\n",
        "print(f\"[INFO] Prediction metrics on the test data:\")\n",
        "prediction_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMajKSVE-QeZ",
        "outputId": "7f0eb5fc-c4fa-49c0-9633-130fa9f55cf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[-3.4188225,  4.0324287],\n",
              "       [ 4.1835074, -3.7533395],\n",
              "       [-3.4261076,  4.0251036],\n",
              "       [ 4.2181334, -3.7787805],\n",
              "       [ 4.2271934, -3.7474325],\n",
              "       [-3.4285955,  4.0277967],\n",
              "       [ 4.2261305, -3.753712 ],\n",
              "       [ 4.234221 , -3.7631276],\n",
              "       [-3.4254518,  4.026401 ],\n",
              "       [-3.42516  ,  4.0130377],\n",
              "       [-3.4310143,  4.0220895],\n",
              "       [-3.4049966,  4.0195637],\n",
              "       [ 4.1876826, -3.7551675],\n",
              "       [-3.4298651,  4.014366 ],\n",
              "       [-3.4137225,  4.0263824],\n",
              "       [ 4.214499 , -3.7714398],\n",
              "       [-3.429452 ,  4.01207  ],\n",
              "       [ 4.1296854, -3.7415898],\n",
              "       [-3.4246876,  4.0210347],\n",
              "       [-3.4265065,  4.02121  ],\n",
              "       [-3.4260614,  4.0203404],\n",
              "       [-3.4294672,  4.0184956],\n",
              "       [ 4.2191544, -3.7405367],\n",
              "       [ 4.1991205, -3.7737446],\n",
              "       [-3.4314303,  4.016989 ],\n",
              "       [-3.4277613,  4.0272956],\n",
              "       [-3.420276 ,  4.013641 ],\n",
              "       [ 4.1938214, -3.7465665],\n",
              "       [-3.4277837,  4.026138 ],\n",
              "       [ 4.201308 , -3.7732322],\n",
              "       [-3.430642 ,  4.020548 ],\n",
              "       [-3.4193938,  4.0225987],\n",
              "       [-3.4299986,  4.021438 ],\n",
              "       [ 4.233394 , -3.7637415],\n",
              "       [-3.4265945,  4.0171022],\n",
              "       [-3.4339755,  4.0108323],\n",
              "       [-3.4308667,  4.022038 ],\n",
              "       [-3.4196062,  4.0237885],\n",
              "       [ 4.2133546, -3.7830784],\n",
              "       [ 4.2126822, -3.7340326],\n",
              "       [-3.4013293,  4.01626  ],\n",
              "       [-3.4193184,  4.0241537],\n",
              "       [-3.417921 ,  4.0207057],\n",
              "       [ 3.443585 , -3.2793148],\n",
              "       [-3.422185 ,  4.0232315],\n",
              "       [-3.4275763,  4.0198736],\n",
              "       [-3.416921 ,  4.0237703],\n",
              "       [-3.4239624,  4.0302143],\n",
              "       [ 4.220668 , -3.774223 ],\n",
              "       [-3.4216669,  4.026774 ]], dtype=float32), label_ids=array([1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1]), metrics={'test_loss': 0.0005204931367188692, 'test_accuracy': 1.0, 'test_runtime': 0.0946, 'test_samples_per_second': 528.493, 'test_steps_per_second': 21.14})"
            ]
          },
          "execution_count": 255,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyZ_QBea-9tB"
      },
      "source": [
        "### Let's get predicted probabilities and evaluate by hand\n",
        "\n",
        "Turning the predicted logits(raw output of the model) to predictions probabilities with torch.softmax then to predicted labels for readability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho9Tsrup-f0h",
        "outputId": "809ec83a-45fb-4e37-b7b2-1b8542aa54fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Test accuracy: 100.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Get prediction probabilities with torch.softmax\n",
        "pred_probs = torch.softmax(torch.tensor(prediction_values), dim=1)\n",
        "\n",
        "# 2. Get the predicted labels\n",
        "pred_labels = torch.argmax(pred_probs, dim=1)\n",
        "\n",
        "# 3. Get the true labels\n",
        "true_labels = tokenized_dataset[\"test\"] [\"label\"]\n",
        "\n",
        "# 4. Compute prediction labels to true labels and get the test accuracy\n",
        "test_accuracy = accuracy_score(y_true=true_labels,\n",
        "                               y_pred=pred_labels)\n",
        "\n",
        "print(f\"[INFO] Test accuracy: {test_accuracy*100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFkLLUaGCXQ7"
      },
      "source": [
        "### Exploring our model's prediction probabilities.\n",
        "\n",
        "It's a very good way to evaluate a model by sorting predictions by prediction probabilities and seeing where the model went wrong."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Hao-1jsMBBRJ",
        "outputId": "5067c45d-4054-4c90-e099-90d4f51d2ffa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"test_predictions_df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"Comforting lamb curry bowl, featuring tender lamb slow-cooked in a flavorful sauce with cumin and coriander, garnished with toasted cumin seeds.\",\n          \"A close-up of a woman practicing yoga in the living room while her dog mimics her poses\",\n          \"Robust beef curry in a hearty bowl, simmered with a medley of spices, tomatoes, and onions, garnished with chopped green onions.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_prob\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          0.9996440410614014,\n          0.9994151592254639\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "test_predictions_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0fee63bb-2bab-43c7-bebc-9502b89d5288\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>true_label</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A slice of pepperoni pizza with a layer of mel...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Red brick fireplace with a mantel serving as a...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A bowl of sliced bell peppers with a sprinkle ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Set of mugs hanging on a hook</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Standing floor lamp providing light next to an...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999656</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fee63bb-2bab-43c7-bebc-9502b89d5288')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0fee63bb-2bab-43c7-bebc-9502b89d5288 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0fee63bb-2bab-43c7-bebc-9502b89d5288');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5c174457-2a06-4c96-a6e8-f3697399c79b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c174457-2a06-4c96-a6e8-f3697399c79b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5c174457-2a06-4c96-a6e8-f3697399c79b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text  true_label  pred_label  \\\n",
              "0  A slice of pepperoni pizza with a layer of mel...           1           1   \n",
              "1  Red brick fireplace with a mantel serving as a...           0           0   \n",
              "2  A bowl of sliced bell peppers with a sprinkle ...           1           1   \n",
              "3                      Set of mugs hanging on a hook           0           0   \n",
              "4  Standing floor lamp providing light next to an...           0           0   \n",
              "\n",
              "   pred_prob  \n",
              "0   0.999420  \n",
              "1   0.999643  \n",
              "2   0.999420  \n",
              "3   0.999664  \n",
              "4   0.999656  "
            ]
          },
          "execution_count": 257,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make a DataFrame of test predictions\n",
        "test_predictions_df = pd.DataFrame({\n",
        "    \"text\": dataset[\"test\"][\"text\"],\n",
        "    \"true_label\": true_labels,\n",
        "    \"pred_label\": pred_labels,\n",
        "    \"pred_prob\": torch.max(pred_probs, dim=1).values\n",
        "})\n",
        "\n",
        "test_predictions_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ZXsEniSFDVMY",
        "outputId": "ee3e3fe6-3912-44a2-91c5-b13cf9920b49"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"test_predictions_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Zucchini in a bowl, sprinkled with basil and served with a side of marinara sauce for a classic, Italian-inspired dish.\",\n          \"A bowl of cherries with a sprig of mint for garnish\",\n          \"Boxes of apples, pears, pineapple, manadrins and oranges at a fruit market\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_prob\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9994139671325684,\n          0.9993997812271118\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-57f371a4-b355-4caa-bc9b-701048af8321\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>true_label</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Set of muffin tins stacked together</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.998798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>A bowl of cherries with a sprig of mint for ga...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>A close-up shot of a cheesy pizza slice being ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>A fruit platter with a variety of exotic fruit...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Cherry tomatoes and mozzarella balls in a bowl...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Boxes of apples, pears, pineapple, manadrins a...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Two handfuls of bananas in a fruit bowl with g...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>A bowl of sliced kiwi with a sprinkle of sugar...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Zucchini in a bowl, sprinkled with basil and s...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Crunchy sushi roll with tempura flakes or pank...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999414</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57f371a4-b355-4caa-bc9b-701048af8321')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57f371a4-b355-4caa-bc9b-701048af8321 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57f371a4-b355-4caa-bc9b-701048af8321');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0b62540f-eb8f-4065-879a-fe1b37bba605\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b62540f-eb8f-4065-879a-fe1b37bba605')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0b62540f-eb8f-4065-879a-fe1b37bba605 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                 text  true_label  pred_label  \\\n",
              "43                Set of muffin tins stacked together           0           0   \n",
              "40  A bowl of cherries with a sprig of mint for ga...           1           1   \n",
              "11  A close-up shot of a cheesy pizza slice being ...           1           1   \n",
              "26  A fruit platter with a variety of exotic fruit...           1           1   \n",
              "9   Cherry tomatoes and mozzarella balls in a bowl...           1           1   \n",
              "42  Boxes of apples, pears, pineapple, manadrins a...           1           1   \n",
              "14  Two handfuls of bananas in a fruit bowl with g...           1           1   \n",
              "46  A bowl of sliced kiwi with a sprinkle of sugar...           1           1   \n",
              "16  Zucchini in a bowl, sprinkled with basil and s...           1           1   \n",
              "31  Crunchy sushi roll with tempura flakes or pank...           1           1   \n",
              "\n",
              "    pred_prob  \n",
              "43   0.998798  \n",
              "40   0.999400  \n",
              "11   0.999404  \n",
              "26   0.999409  \n",
              "9    0.999412  \n",
              "42   0.999412  \n",
              "14   0.999413  \n",
              "46   0.999413  \n",
              "16   0.999414  \n",
              "31   0.999414  "
            ]
          },
          "execution_count": 258,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show 10 examples with low prediction probability\n",
        "test_predictions_df.sort_values(\"pred_prob\", ascending=True).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jk_AreHHcoX"
      },
      "source": [
        "### Making and inspecting predictions on custom data.\n",
        "\n",
        "Two main ways to perform inference:\n",
        "1. **Pipeline Mode** - Using `transformers.pipeline` to load our model and perform text classification.\n",
        "2. **PyTorch Mode** - Using a combination of `transformers.AutoTokenizer` and `transformers.AutoModelForSequenceClassification` and passing each our target model name.\n",
        "\n",
        "Each mode supports:\n",
        "\n",
        "1. Predictions one at a time (fast but can be slower with many many samples).\n",
        "2. Batches of predictions at a time(faster but up to a point, depends on the batch size)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu48AaHTJF8h",
        "outputId": "0ea7c749-291e-48dc-d181-86d6927ca625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Setup our device for making predictions\n",
        "\n",
        "def set_device():\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "  elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
        "    device = torch.device(\"mps\")\n",
        "  else:\n",
        "    device = torch.device(\"cpu\")\n",
        "  return device\n",
        "\n",
        "DEVICE = set_device()\n",
        "print(f\"[INFO] Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0b6yK9JLktH"
      },
      "source": [
        "### Making predictions with pipeline mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqCLl5NSMUGF"
      },
      "outputs": [],
      "source": [
        "local_model_path = \"models/food_not_food_distilbert-base-uncased_text_classification_model\"\n",
        "\n",
        "huggingface_model_path = \"LizzChall/food_not_food_distilbert-base-uncased_text_classification_model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMglOFkBLOZD",
        "outputId": "764f0aed-b7a3-4a22-9523-29419b1e7116"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<transformers.pipelines.text_classification.TextClassificationPipeline at 0x7ad838f75310>"
            ]
          },
          "execution_count": 261,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# Set the batch size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create an instance of transformers.pipeline\n",
        "food_not_food_classifier = pipeline(task=\"text-classification\",\n",
        "                                    model= local_model_path,\n",
        "                                    device=DEVICE,\n",
        "                                    top_k=1,\n",
        "                                    batch_size=BATCH_SIZE)\n",
        "\n",
        "food_not_food_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC4lLFvyPRx6",
        "outputId": "b293a7ff-8d32-4217-b983-eff311daa126"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[{'label': 'not_food', 'score': 0.9995489716529846}]]"
            ]
          },
          "execution_count": 262,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_not_food_sentence = \"Text to test the pipeline mode.\"\n",
        "food_not_food_classifier(test_not_food_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68MgLgM-QFiz",
        "outputId": "123dec6a-fc80-46a2-aa13-2efdbac62157"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[{'label': 'food', 'score': 0.9993822574615479}]]"
            ]
          },
          "execution_count": 263,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_custom_sentence = \"For breakfast I had waffles, sausages, and eggs.\"\n",
        "food_not_food_classifier(test_custom_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIrv8KYmSCjt"
      },
      "outputs": [],
      "source": [
        "del food_not_food_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp2fKtffQOjL",
        "outputId": "c45b1171-f6fe-4634-8e59-68ef7c699cda"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[{'label': 'not_food', 'score': 0.9995489716529846}]]"
            ]
          },
          "execution_count": 265,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use pipeline with a model from Hugging Face\n",
        "food_not_food_classifier = pipeline(task=\"text-classification\",\n",
        "                                    model=huggingface_model_path,\n",
        "                                    device=DEVICE,\n",
        "                                    top_k=1,\n",
        "                                    batch_size=BATCH_SIZE)\n",
        "\n",
        "food_not_food_classifier(test_not_food_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djCdto3eS_pJ"
      },
      "source": [
        "### Making multiple predictions at the same time with batch predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZrcqvI-SJkz",
        "outputId": "bc4a5ef9-6b70-430d-e207-c4b29b73f9aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[{'label': 'not_food', 'score': 0.9983888864517212}],\n",
              " [{'label': 'not_food', 'score': 0.9993321299552917}],\n",
              " [{'label': 'not_food', 'score': 0.9987264275550842}],\n",
              " [{'label': 'not_food', 'score': 0.99951171875}],\n",
              " [{'label': 'not_food', 'score': 0.9994196891784668}],\n",
              " [{'label': 'not_food', 'score': 0.9994412064552307}],\n",
              " [{'label': 'not_food', 'score': 0.9991315007209778}],\n",
              " [{'label': 'food', 'score': 0.9993730187416077}],\n",
              " [{'label': 'food', 'score': 0.9985628724098206}]]"
            ]
          },
          "execution_count": 266,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a list of sentences to make predictions on\n",
        "sentences = [\n",
        "    \"I whipped up a fresh batch of code, but it seems to have a syntax error.\",\n",
        "    \"We need to marinate these ideas overnight before presenting them to the client.\",\n",
        "    \"The new software is definitely a spicy upgrade, taking some time to get used to.\",\n",
        "    \"Her social media post was the perfect recipe for a viral sensation.\",\n",
        "    \"He served up a rebuttal full of facts, leaving his opponent speechless.\",\n",
        "    \"The team needs to simmer down a bit before tackling the next challenge.\",\n",
        "    \"The presentation was a delicious blend of humor and information, keeping the audience engaged.\",\n",
        "    \"A beautiful array of fake wax foods (shokuhin sampuru) in the front of a Japanese restaurant.\",\n",
        "    \"My favoruite food is biltong!\"\n",
        "]\n",
        "\n",
        "food_not_food_classifier(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FBopu7CTVuD",
        "outputId": "6c797e0f-4bf0-4b51-d900-d5dea81285ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[{'label': 'food', 'score': 0.9994107484817505}],\n",
              " [{'label': 'food', 'score': 0.9993402361869812}],\n",
              " [{'label': 'food', 'score': 0.9994082450866699}],\n",
              " [{'label': 'food', 'score': 0.9993957281112671}],\n",
              " [{'label': 'food', 'score': 0.9993698000907898}],\n",
              " [{'label': 'food', 'score': 0.9993522763252258}],\n",
              " [{'label': 'food', 'score': 0.9990948438644409}],\n",
              " [{'label': 'food', 'score': 0.9983200430870056}],\n",
              " [{'label': 'food', 'score': 0.9993962049484253}],\n",
              " [{'label': 'food', 'score': 0.999403715133667}]]"
            ]
          },
          "execution_count": 267,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "food_captions = [\n",
        "    \"A steaming plate of pad thai, garnished with fresh lime wedges.\",\n",
        "    \"The aroma of freshly baked croissants wafted through the air.\",\n",
        "    \"Savoring the flavors of a traditional Indian curry.\",\n",
        "    \"A juicy burger and crispy fries on a sunny summer day.\",\n",
        "    \"Fresh sushi rolls, expertly crafted with love and care.\",\n",
        "    \"The sweet scent of ripe strawberries filled the room.\",\n",
        "    \"A warm, gooey cookie straight from the oven.\",\n",
        "    \"The art of making pasta from scratch, a labor of love.\",\n",
        "    \"A decadent chocolate cake, perfect for special occasions.\",\n",
        "    \"The vibrant colors of a fruit salad, a feast for the eyes.\"\n",
        "]\n",
        "\n",
        "food_not_food_classifier(food_captions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEofB95NUJ70",
        "outputId": "930c0c8b-766c-47f8-f249-414837ead4c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[{'label': 'not_food', 'score': 0.9993268251419067}],\n",
              " [{'label': 'not_food', 'score': 0.9995966553688049}],\n",
              " [{'label': 'not_food', 'score': 0.9994754195213318}],\n",
              " [{'label': 'not_food', 'score': 0.99953293800354}],\n",
              " [{'label': 'not_food', 'score': 0.9996356964111328}],\n",
              " [{'label': 'not_food', 'score': 0.9996178150177002}],\n",
              " [{'label': 'not_food', 'score': 0.9995614886283875}],\n",
              " [{'label': 'not_food', 'score': 0.9995792508125305}],\n",
              " [{'label': 'not_food', 'score': 0.9995771050453186}],\n",
              " [{'label': 'food', 'score': 0.9991008043289185}]]"
            ]
          },
          "execution_count": 268,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "not_food_captions = [\n",
        "    \"A beautiful sunset over the rolling hills of Tuscany.\",\n",
        "    \"The sound of waves crashing against the shore, soothing the soul.\",\n",
        "    \"A stunning work of art, created with passion and precision.\",\n",
        "    \"The majestic beauty of a mountain range, inspiring awe.\",\n",
        "    \"A cozy living room, filled with warmth and comfort.\",\n",
        "    \"The intricate details of a handmade clock, a testament to craftsmanship.\",\n",
        "    \"A serene forest, teeming with life and tranquility.\",\n",
        "    \"The vibrant lights of a city skyline, pulsating with energy.\",\n",
        "    \"A breathtaking waterfall, a wonder of nature.\",\n",
        "    \"The soft petals of a flower, delicate and lovely.\"\n",
        "]\n",
        "\n",
        "food_not_food_classifier(not_food_captions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB7nPWHpUUNU",
        "outputId": "982670ea-97df-430b-87c5-fcbf675e133d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[{'label': 'not_food', 'score': 0.9579307436943054}],\n",
              " [{'label': 'not_food', 'score': 0.9990371465682983}],\n",
              " [{'label': 'food', 'score': 0.9991015195846558}],\n",
              " [{'label': 'not_food', 'score': 0.9992483258247375}],\n",
              " [{'label': 'not_food', 'score': 0.999452531337738}],\n",
              " [{'label': 'not_food', 'score': 0.999397873878479}],\n",
              " [{'label': 'not_food', 'score': 0.9994565844535828}],\n",
              " [{'label': 'not_food', 'score': 0.9992189407348633}],\n",
              " [{'label': 'food', 'score': 0.9992615580558777}],\n",
              " [{'label': 'not_food', 'score': 0.9995504021644592}]]"
            ]
          },
          "execution_count": 269,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusing_captions = [\n",
        "    \"Bite into the weekend with a fresh start.\",\n",
        "    \"The sauce of sarcasm dripped from her words.\",\n",
        "    \"A pinch of salt in the wound made it hard to forgive.\",\n",
        "    \"The recipe for success involves hard work and dedication.\",\n",
        "    \"A taste of freedom was exhilarating, but short-lived.\",\n",
        "    \"The flavors of nostalgia washed over me as I flipped through old photos.\",\n",
        "    \"A dash of drama was added to the meeting with the CEO's announcement.\",\n",
        "    \"The bitter truth was hard to swallow.\",\n",
        "    \"A spoonful of sugar helps the medicine go down, but not in this case.\",\n",
        "    \"The aroma of opportunity filled the air at the career fair.\"\n",
        "]\n",
        "\n",
        "food_not_food_classifier(confusing_captions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BngxyJ0HVHJY"
      },
      "source": [
        "### Time our model across larger sample sizes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7PSjy_cUnWt",
        "outputId": "f4b91073-2baf-4906-bbe3-69d37d7e469f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Number of sentences: 1008\n",
            "[INFO]: Total time for making predictions on 1008 samples one at a time: 4.658188581466675s\n",
            "[INFO] Average time per predictions one at a time: 0.004621218830820114s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Create 1000 sentences\n",
        "sentences_1000 = sentences * 112\n",
        "\n",
        "# Time how long it takes to make predictions on all sentences (one at a time)\n",
        "print(f\"[INFO] Number of sentences: {len(sentences_1000)}\")\n",
        "start_time_one_at_a_time = time.time()\n",
        "for sentence in sentences_1000:\n",
        "  # Make a prediction\n",
        "  food_not_food_classifier(sentence)\n",
        "end_time_one_at_a_time = time.time()\n",
        "\n",
        "total_time_one_at_a_time = end_time_one_at_a_time - start_time_one_at_a_time\n",
        "avg_time_per_pred = total_time_one_at_a_time / len(sentences_1000)\n",
        "print(f\"[INFO]: Total time for making predictions on {len(sentences_1000)} samples one at a time: {total_time_one_at_a_time}s\")\n",
        "print(f\"[INFO] Average time per predictions one at a time: {avg_time_per_pred}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMrqIsdvVdPb",
        "outputId": "512a42a6-9c58-43a6-a46f-79d912336c77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Number of sentences: 90\n",
            "[INFO] Inference time for 90 sentences: 0.075491s\n",
            "[INFO] Average inference time per sentence: 0.00083879s\n",
            "\n",
            "[INFO] Number of sentences: 900\n",
            "[INFO] Inference time for 900 sentences: 0.739987s\n",
            "[INFO] Average inference time per sentence: 0.00082221s\n",
            "\n",
            "[INFO] Number of sentences: 9000\n",
            "[INFO] Inference time for 9000 sentences: 7.757358s\n",
            "[INFO] Average inference time per sentence: 0.00086193s\n",
            "\n",
            "[INFO] Number of sentences: 90000\n",
            "[INFO] Inference time for 90000 sentences: 78.385847s\n",
            "[INFO] Average inference time per sentence: 0.00087095s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's now use batches\n",
        "for i in [10, 100, 1000, 10000]:\n",
        "  sentences_big = sentences * i\n",
        "  print(f\"[INFO] Number of sentences: {len(sentences_big)}\")\n",
        "\n",
        "  start_time_batches = time.time()\n",
        "  food_not_food_classifier(sentences_big)\n",
        "  end_time_batches = time.time()\n",
        "\n",
        "  total_time_per_all_sentences_batch_mode = end_time_batches - start_time_batches\n",
        "  avg_time_per_pred_batch_mode = total_time_per_all_sentences_batch_mode / len(sentences_big)\n",
        "\n",
        "  print(f\"[INFO] Inference time for {len(sentences_big)} sentences: {round(total_time_per_all_sentences_batch_mode, 6)}s\")\n",
        "  print(f\"[INFO] Average inference time per sentence: {round(avg_time_per_pred_batch_mode, 8)}s\")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAEyGMB7ZM8S"
      },
      "source": [
        "### Making predictions with PyTorch.\n",
        "\n",
        "Steps with PyTorch predictions:\n",
        "\n",
        "1. Create the tokenizer with `AutoTokenizer`\n",
        "2. Create the model with `AutoModel` (AutoModelForSequenceClassification)\n",
        "3. Tokenize text with 1\n",
        "4. Make predictions with 2\n",
        "5. Format predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjn8VL6UYmjE",
        "outputId": "1532db41-5ae1-4f1f-f70e-a00573ecbc0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  1037, 12090,  6302,  1997,  1037,  5127,  1997,  6949,  8808,\n",
              "          1010,  9370,  2007, 12428,  6949,  1998, 13137, 20968,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "execution_count": 272,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Setup the model path\n",
        "model_path = \"models/food_not_food_distilbert-base-uncased_text_classification_model\"\n",
        "\n",
        "# Create an example to predict on\n",
        "sample_food_text = \"A delicious photo of a plate of cream cheese, topped with whipped cream and strawberries.\"\n",
        "\n",
        "# Create an instance of AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_path)\n",
        "inputs = tokenizer(sample_food_text,\n",
        "                   return_tensors=\"pt\")\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHf9Nu7raxFM"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Load our  text classification model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9ER5ovNa_Jl",
        "outputId": "3fb210b4-1eed-4dae-8217-92f02efe250d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Outputs: SequenceClassifierOutput(loss=None, logits=tensor([[-3.4272,  4.0245]]), hidden_states=None, attentions=None)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "  outputs = model(**inputs)\n",
        "  print(f\"[INFO] Outputs: {outputs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7aKpwS7biZ0",
        "outputId": "2c6dc92b-4f98-4e12-f3a0-126724483c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: A delicious photo of a plate of cream cheese, topped with whipped cream and strawberries.\n",
            "[INFO] Predicted class label: food\n",
            "[INFO] Predicted class probability: 0.9994199275970459\n"
          ]
        }
      ],
      "source": [
        "# Convert logits to prediction probability plus label\n",
        "predicted_class_id = outputs.logits.argmax().item()\n",
        "predicted_prob = torch.softmax(outputs.logits, dim=1).max().item()\n",
        "\n",
        "print(f\"Text: {sample_food_text}\")\n",
        "print(f\"[INFO] Predicted class label: {model.config.id2label[predicted_class_id]}\")\n",
        "print(f\"[INFO] Predicted class probability: {predicted_prob}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy2g0cUncN8k",
        "outputId": "264a234b-7129-4dbe-ff1c-51ac7fe37c8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[{'label': 'food', 'score': 0.9994199275970459}]]"
            ]
          },
          "execution_count": 276,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "food_not_food_classifier(sample_food_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aakXYw5vc_kh"
      },
      "source": [
        "### Putting it all together.\n",
        "\n",
        "End-to-end from data import to model evaluation to model saving for our text classification project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884,
          "referenced_widgets": [
            "8da7b58d73dd46529aea52ee1ce9bd6d",
            "57ebe45581414b23b0bb91b17d0bf262",
            "5086d084ca644b06b3c7c6a505ab861d",
            "1d6a85b024cb41d2aed21806336390fb",
            "0fc3c50494864b9fa7de82bff1e391c4",
            "5a77a6c40ecf4f30b51390a1737ceb93",
            "d8e1f5cd24ce4908a8d79e039640dc51",
            "010bcf8210454f47ac7c405a2c008d38",
            "b1291a0a099f45009abf5142fe383774",
            "5d58e5aad9324a0892cb3d291a97541e",
            "831cbb2b48d34b3d8834604a6fa61a89",
            "a1256b04d84a4fe5ad1ce4556a7faf14",
            "6dc50f24793e4934962f3d1ecb340756",
            "5f675f63b1c34837a5c6f9005ec97560",
            "20e9a0a5e25b448a9a8204e959d24926",
            "9b1cc3bf2758406f925febcd3ccd9583",
            "cb23c6b37c6e4cafa8cd4a0f06a55f8a",
            "1fd83397bf03477aa8e22a0e91534ca2",
            "606473521f0b48f0a8546713f2a9f46b",
            "96361a55f59d48eaaa06d8e3ecbb0643",
            "1e215c9b76624de6a2de8924160cd00f",
            "7ab66c88bc694f75a97e95feed49a2b4",
            "78636f00a8a24ce5bfa95e9ca4a29669",
            "029a422f4aab4e0b9f7172db47d6bcab",
            "75f60fecfbc9451f998773723c7049c7",
            "1587ac3e6b924678910df0d37e801113",
            "c846b81e899b4f0cb12ed157eba0b343",
            "1f3b2bccf80546f195e54bbf69b6f1df",
            "75aac1e62a1d417f8ee73dadfca72d86",
            "0a961b2d1f66461b95829333c44e991b",
            "49c2121c6a35464284b3f3e4054f4136",
            "d057c46d484c4c62a3935f7c461f3dfb",
            "7c938e76796e483394d25da60c2b1317",
            "795201ccaa8f4b469837f512f6ac5cc7",
            "973b59b0da464556a440135285a03c4a",
            "0c71356051e049bfb60a22a49fda627b",
            "eb70c1f4059642148512cd2681d4b5e5",
            "75029d917cd64089848bfc7b1c63b882",
            "029af4211c574573996d8d3c4c45b163",
            "35f8990e3a804446843ea6e5c4de6788",
            "f64ccd36d768407bb4d5113750dd5b7c",
            "d028bad0721040df9d798a0e5e1f89e7",
            "72e2694f30604ae8bffa5f763d586352",
            "3fb335d21ae64b93bc6ba091df370ee3"
          ]
        },
        "id": "Tg7-wbNTc44k",
        "outputId": "6676aec6-ccf9-4202-89dc-5a48b343f9b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Creating directory for saving models: models/food_not_food_text_classifier_distilbert-base-uncased\n",
            "[INFO] Downloading dataset from Hugging Face Hub, name: mrdbourke/learn_hf_food_not_food_image_captions\n",
            "[INFO] Tokenizing text for model training with tokenizer: distilbert/distilbert-base-uncased\n",
            "[INFO] Loading model: distilbert/distilbert-base-uncased\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1701595809.py:101: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Model loading complete!\n",
            "[INFO] Commencing model training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70/70 01:09, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.338800</td>\n",
              "      <td>0.041322</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.019300</td>\n",
              "      <td>0.005754</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.002047</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>0.001152</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000819</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.000670</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.000593</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000550</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000528</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000520</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Model training complete, saving model to local path: models/food_not_food_text_classifier_distilbert-base-uncased\n",
            "[INFO] Uploading model to Hugging Face Hub...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8da7b58d73dd46529aea52ee1ce9bd6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1256b04d84a4fe5ad1ce4556a7faf14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78636f00a8a24ce5bfa95e9ca4a29669",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...uncased/model.safetensors:  12%|#2        | 33.1MB /  268MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "795201ccaa8f4b469837f512f6ac5cc7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...uncased/training_args.bin:  30%|##9       | 1.74kB / 5.84kB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Model upload complete, model available at: https://huggingface.co/LizzChall/food_not_food_text_classifier_distilbert-base-uncased/tree/main/\n",
            "[INFO] Performing evaluation on test dataset...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Prediction metrics on the test data:\n",
            "{'test_accuracy': 1.0,\n",
            " 'test_loss': 0.0005204931367188692,\n",
            " 'test_runtime': 0.0907,\n",
            " 'test_samples_per_second': 551.364,\n",
            " 'test_steps_per_second': 22.055}\n"
          ]
        }
      ],
      "source": [
        "# 1. Import necessary packages\n",
        "import pprint\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import datasets\n",
        "import evaluate\n",
        "\n",
        "from transformers import pipeline\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "#2. Setup variables for model training and saving pipeline\n",
        "DATASET_NAME = \"mrdbourke/learn_hf_food_not_food_image_captions\"\n",
        "MODEL_NAME = \"distilbert/distilbert-base-uncased\"\n",
        "MODEL_SAVE_DIR_NAME = \"models/food_not_food_text_classifier_distilbert-base-uncased\"\n",
        "\n",
        "# 3. Create a directory for saving models\n",
        "print(f\"[INFO] Creating directory for saving models: {MODEL_SAVE_DIR_NAME}\")\n",
        "model_save_dir = Path(MODEL_SAVE_DIR_NAME)\n",
        "model_save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 4. Load and preprocess the dataset from Hugging Face Hub\n",
        "print(f\"[INFO] Downloading dataset from Hugging Face Hub, name: {DATASET_NAME}\")\n",
        "dataset = datasets.load_dataset(DATASET_NAME)\n",
        "\n",
        "# Create mappings from id2label and label2id (adjust these for your target dataset, can also create these programmatically)\n",
        "id2labe = {0: \"not_food\", 1: \"food\"}\n",
        "label2id = {\"not_food\": 0, \"food\":1}\n",
        "\n",
        "# Create function to map IDs to labels in dataset\n",
        "def map_labels_to_number(example):\n",
        "  example[\"label\"] = label2id[example[\"label\"]]\n",
        "  return example\n",
        "\n",
        "# Map preprocessing function to dataset\n",
        "dataset = dataset[\"train\"].map(map_labels_to_number)\n",
        "\n",
        "# Split the dataset into train/test sets\n",
        "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "# 5. Import a tokenizer and map it to our dataset\n",
        "print(f\"[INFO] Tokenizing text for model training with tokenizer: {MODEL_NAME}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=MODEL_NAME,\n",
        "                                          use_fast=True)\n",
        "\n",
        "# Create a preprocessing function to tokenize text samples\n",
        "def tokenize_text(examples):\n",
        "  return tokenizer(examples[\"text\"],\n",
        "                   padding=True,\n",
        "                   truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(function=tokenize_text,\n",
        "                                batched=True,\n",
        "                                batch_size=1000)\n",
        "\n",
        "# 6. Set up an evaluation metric & function to evaluate our model\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_accuracy(predictions_and_labels):\n",
        "  predictions, labels = predictions_and_labels\n",
        "\n",
        "  if len(predictions.shape) >= 2:\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "  return accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# 7. Import a model and prepare it for training\n",
        "print(f\"[INFO] Loading model: {MODEL_NAME}\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    pretrained_model_name_or_path=MODEL_NAME,\n",
        "    num_labels=2,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "print(f\"[INFO] Model loading complete!\")\n",
        "\n",
        "# Setup TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_save_dir,\n",
        "    learning_rate=0.0001,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=10,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=3,\n",
        "    use_cpu=False,\n",
        "    seed=42,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        "    push_to_hub=False,\n",
        "    hub_private_repo=False\n",
        ")\n",
        "\n",
        "# Create Trainer instance and train model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset['train'],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_accuracy\n",
        "\n",
        ")\n",
        "\n",
        "# 8. Train the model on our text dataset\n",
        "print(f\"[INFO] Commencing model training...\")\n",
        "results = trainer.train()\n",
        "\n",
        "# 9. Save the trained model (note: this will overwrite our previous model)\n",
        "print(f\"[INFO] Model training complete, saving model to local path: {model_save_dir}\")\n",
        "trainer.save_model(output_dir=model_save_dir)\n",
        "\n",
        "# 10. Push the model to the Hugging Face Hub\n",
        "print(f\"[INFO] Uploading model to Hugging Face Hub...\")\n",
        "model_upload_url = trainer.push_to_hub(\n",
        "    commit_message=\"Uploading food not food text classifier model (putting it all together)\"\n",
        ")\n",
        "print(f\"[INFO] Model upload complete, model available at: {model_upload_url}\")\n",
        "\n",
        "# 11. Evaluate the model on the test data\n",
        "print(f\"[INFO] Performing evaluation on test dataset...\")\n",
        "\n",
        "predictions_all = trainer.predict(tokenized_dataset[\"test\"])\n",
        "predictions_values = predictions_all.predictions\n",
        "predictions_metrics = predictions_all.metrics\n",
        "\n",
        "print(f\"[INFO] Prediction metrics on the test data:\")\n",
        "pprint.pprint(predictions_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbBpZmyOf661",
        "outputId": "77b8fe59-1507-4a4b-9bb0-767c2309f6bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Testing the model on a custom sample...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[{'label': 'food', 'score': 0.9994199275970459}]]"
            ]
          },
          "execution_count": 307,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 12. Testing the model on a custom sample to make certain that it works\n",
        "from transformers import pipeline\n",
        "food_not_food_classifier = pipeline(task=\"text-classification\",\n",
        "                                    model= model_save_dir,\n",
        "                                    device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.ddevice(\"cpu\"),\n",
        "                                    top_k=1,\n",
        "                                    batch_size=32)\n",
        "\n",
        "custom_sample = \"A delicious photo of a plate of cream cheese, topped with whipped cream and strawberries.\"\n",
        "print(f\"[INFO] Testing the model on a custom sample...\")\n",
        "\n",
        "food_not_food_classifier(custom_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgDEb7UY6DYx"
      },
      "source": [
        "### Turning our model into a demo.\n",
        "\n",
        "We're going to create a machine learning demo using Gradio.\n",
        "\n",
        "Workflow:\n",
        "1. âœ… Create and preprocess data\n",
        "2. âœ… Define the model we'd like to use for our problem (in our case it will be the `distilbert/distilbert-base-uncased` model found here:   https://huggingface.co/distilbert/distilbert-base-uncased)\n",
        "3. âœ… Define training arguments for training our model using `transformers.TrainingArguments`\n",
        "\n",
        "   - These are also known as \"hyperparameters\" = settings on your model that you can adjust\n",
        "   - Parameters = weightes/patterns in the model that get updated automatically\n",
        "\n",
        "4. âœ… Pass `TrainingArguments` to an instance of `transformers.Trainer`\n",
        "5. âœ… Train the model by calling `Trainer.train()`\n",
        "6. âœ… Save the model (to our local machine or to the HuggingFace Hub)\n",
        "7. âœ… Evaluate the trained model by making and inspecting predictions on the test data (and our own custom data)\n",
        "8. Turn the model into a shareable demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-LmkQCC7n9D"
      },
      "source": [
        "### Creating a function to perform inference.\n",
        "\n",
        "1. Take an input of string.\n",
        "2. Setup a text classification pipeline.\n",
        "3. Get the output from the pipeline.\n",
        "4. Return the output from the pipeline in step 3 as a formatted dictionary with the format:\n",
        "`{\"label_1\": probability_1, \"label_2\": probability_2}`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsW6nJenqKku",
        "outputId": "06930bf4-a422-4ce2-ef67-b9d94dc67959"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'food': 0.9991205334663391, 'not_food': 0.0008794725290499628}"
            ]
          },
          "execution_count": 308,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Dict\n",
        "\n",
        "# 1. Create a function which takes text as input\n",
        "def food_not_food_classifier(text: str) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Takes an input string of text and classifies it into food/not_food in the form of a dictionary.\n",
        "    \"\"\"\n",
        "\n",
        "    # 2. Setup the pipeline to use the local model (or Hugging Face model path)\n",
        "    food_not_food_classifier = pipeline(task=\"text-classification\",\n",
        "                                        model=local_model_path,\n",
        "                                        batch_size=32,\n",
        "                                        device=\"cuda\" if torch.cuda.is_available() else \"cpu\", # set the device to work in any environment\n",
        "                                        top_k=None) # return all possible scores (not just top-1)\n",
        "\n",
        "    # 3. Get outputs from pipeline (as a list of dicts)\n",
        "    outputs = food_not_food_classifier(text)[0]\n",
        "\n",
        "    # 4. Format output for Gradio (e.g. {\"label_1\": probability_1, \"label_2\": probability_2})\n",
        "    output_dict = {}\n",
        "    for item in outputs:\n",
        "        output_dict[item[\"label\"]] = item[\"score\"]\n",
        "\n",
        "    return output_dict\n",
        "\n",
        "# Test out the function\n",
        "food_not_food_classifier(\"My lunch today was chicken and salad\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppCKd1J3Bv8U"
      },
      "source": [
        "### Building a small Gradio demo to run locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "tlXRWCiQB1Er",
        "outputId": "3cf8d1db-eb0d-4a18-f381-9b256bb34282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3c54e73b44ff796842.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://3c54e73b44ff796842.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 309,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import Gradio\n",
        "import gradio as gr\n",
        "\n",
        "# Create a gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=food_not_food_classifier,\n",
        "    inputs=\"text\",\n",
        "    outputs=gr.Label(num_top_classes=2),\n",
        "    title=\"Food Not Food Classifier\",\n",
        "    description=\"A text classifier to determine if a sentence or text is about food or not.\",\n",
        "    examples=[\n",
        "        [\"I'm craving a juicy burger and crispy fries right now!\"],\n",
        "        [\"The new smartphone features an impressive camera and sleek design.\"]\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAblVnOgEond"
      },
      "source": [
        "### Making our demo publicly accessible.\n",
        "\n",
        "There are two main ways to make our demo pubicly accessible with Hugging Face Spaces:\n",
        "\n",
        "1. Manually - We can go to huggingface.co/spaces -> \"Create new space\" -> add our files and publish!\n",
        "2. Programmatically - We can use the Hugging Face Hub Python API and add our files to a Space with code.\n",
        "\n",
        "We're going to create these three files to create a Space programmatically:\n",
        "1. `app.py` - This is the main app with functionality of our demo.\n",
        "2. `requirements.txt` - These are the dependencies which our app will require.\n",
        "3. `README.md` - This will explain what the project/demo is about.\n",
        "\n",
        "We'll create these files with the following file structure:\n",
        "\n",
        "```\n",
        "demos/\n",
        "â””â”€â”€ food_not_food_text_classifier/\n",
        "    â”œâ”€â”€ app.py\n",
        "    â”œâ”€â”€ README.md\n",
        "    â””â”€â”€ requirements.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJHdkdWGG7Fs"
      },
      "source": [
        "### Making a directory to store our demo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDycvqEcEBlh"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Make directory for demos\n",
        "demos_dir = Path(\"../demos\")\n",
        "demos_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Create a folder for the food_not_food_text_classifier demo\n",
        "food_not_food_text_classifier_demo_dir = Path(demos_dir, \"food_not_food_text_classifier\")\n",
        "food_not_food_text_classifier_demo_dir.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfESy1IZISyt"
      },
      "source": [
        "### Making an app.py file.\n",
        "\n",
        "In the `app.py` file we are going to:\n",
        "1. Import packages.\n",
        "2. Define our function to use our model (this will work with Grdio).\n",
        "3. Create a demo with Gradio.\n",
        "4. Run the demo with `demo.launch()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKt-AixSH-Hz",
        "outputId": "9ab715b2-f1bd-47dd-bf69-b4b92ab65f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../demos/food_not_food_text_classifier/app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../demos/food_not_food_text_classifier/app.py\n",
        "import torch\n",
        "import gradio as gr\n",
        "\n",
        "from typing import Dict\n",
        "from transformers import pipeline\n",
        "\n",
        "# Define our function to use with our model\n",
        "def food_not_food_classifier(text: str) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Takes an input string of text and classifies it into food/not_food in the form of a dictionary.\n",
        "    \"\"\"\n",
        "\n",
        "    # Setup the pipeline to use the local model (or Hugging Face model path)\n",
        "    food_not_food_classifier = pipeline(task=\"text-classification\",\n",
        "                                        model=\"LizzChall/food_not_food_text_classifier_distilbert-base-uncased\",\n",
        "                                        batch_size=32,\n",
        "                                        device=\"cuda\" if torch.cuda.is_available() else \"cpu\", # set the device to work in any environment\n",
        "                                        top_k=None) # return all possible scores (not just top-1)\n",
        "\n",
        "    # Get outputs from pipeline (as a list of dicts)\n",
        "    outputs = food_not_food_classifier(text)[0]\n",
        "\n",
        "    # Format output for Gradio (e.g. {\"label_1\": probability_1, \"label_2\": probability_2})\n",
        "    output_dict = {}\n",
        "    for item in outputs:\n",
        "        output_dict[item[\"label\"]] = item[\"score\"]\n",
        "\n",
        "    return output_dict\n",
        "\n",
        "# 3. Create a Gradio interface with details about our app\n",
        "description = \"\"\"\n",
        "A text classifier to determine if a sentence is about food or not food.\n",
        "\n",
        "Fine-tuned from [DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased) on a [small dataset of food and not food text](https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions).\n",
        "\n",
        "See [source code](https://github.com/LizzieChall/huggingface_food_not_food_text_classification_demo/blob/main/huggingface_text_classification.ipynb).\n",
        "\"\"\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=food_not_food_classifier,\n",
        "    inputs=\"text\",\n",
        "    outputs=gr.Label(num_top_classes=2),\n",
        "    title=\"ðŸ¥‘ðŸš«ðŸ—Food Not Food Classifier\",\n",
        "    description=description,\n",
        "    examples=[\n",
        "        [\"I'm craving a juicy burger and crispy fries right now!\"],\n",
        "        [\"The new smartphone features an impressive camera and sleek design.\"]\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 4. Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "  demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1oFDdmQMqlM"
      },
      "source": [
        "### Making a README file.\n",
        "\n",
        "This file is in markdown format, with a special YAML block at the top."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilyU4PlIMTIt",
        "outputId": "fb58ba70-f96b-44ba-e8b8-da7c0187f949"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../demos/food_not_food_text_classifier/README.md\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../demos/food_not_food_text_classifier/README.md\n",
        "\n",
        "---\n",
        "title: Food Not Food Text Classifier\n",
        "emoji: ðŸ¥‘ðŸš«ðŸ—\n",
        "colorFrom: pink\n",
        "colorTo: blue\n",
        "sdk: gradio\n",
        "sdk_version: 5.47.2\n",
        "app_file: app.py\n",
        "pinned: true\n",
        "license: apache-2.0\n",
        "---\n",
        "\n",
        "# ðŸ¥‘ðŸš«ðŸ— Food Not Food Text Classifier\n",
        "\n",
        "Small demo to showcase a text classifier to determine if a sentence is about food or not food.\n",
        "\n",
        "DistillBERT model fine-tuned on a small synthetic dataset of 250 generated [Food or Not Food image captions.](https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions).\n",
        "\n",
        "[Source code notebook](https://github.com/LizzieChall/huggingface_food_not_food_text_classification_demo/blob/main/huggingface_text_classification.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG6g9j2iO8TI"
      },
      "source": [
        "### Making a requirements file.\n",
        "\n",
        "This file is going to tell our Hugging Face Space which versions/ which packages to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41VwZRiEO3O6",
        "outputId": "e85a5294-c8a0-411a-95d4-dd1ba024ef40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ../demos/food_not_food_text_classifier/requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile ../demos/food_not_food_text_classifier/requirements.txt\n",
        "gradio\n",
        "torch\n",
        "transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcPlYdmgPpPj"
      },
      "source": [
        "### Uploading our demo to Hugging Face Spaces.\n",
        "\n",
        "We will be using the Hugging Face Hub Python API.\n",
        "\n",
        "To get our demo hosted on Hugging Face Spaces weâ€™ll go through the following steps:\n",
        "\n",
        "1. Import the required methods from the `huggingface_hub` package, including create_repo, get_full_repo_name, upload_file (optional, weâ€™ll be using upload_folder) and upload_folder.\n",
        "2. Define the demo folder weâ€™d like to upload as well as the different parameters for the Hugging Face Space such as repo type (\"space\"), our target Space name, the target Space SDK (\"gradio\"), our Hugging Face token with write access (optional if it already isnâ€™t setup).\n",
        "3. Create a repository on Hugging Face Spaces using the `huggingface_hub.create_repo` method and filling out the appropriate parameters.\n",
        "4. Get the full name of our created repository using the `huggingface_hub.get_full_repo_name` method.\n",
        "5. Upload the contents of our target demo folder (../demos/food_not_food_text_classifier/) to Hugging Face Hub with `huggingface_hub.upload_folder`.\n",
        "6. Hope it all works and inspect the results! ðŸ¤ž\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v6_f-edPezB",
        "outputId": "d8d5abea-9796-4832-aaf1-d9345bb0dd13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Creating Space repository on Hugging Face Hub...\n",
            "[INFO] Full Hugging Face Hub repo name: LizzChall/food_not_food_text_classifier_demo\n",
            "[INFO] Uploading ../demos/food_not_food_text_classifier to repo: LizzChall/food_not_food_text_classifier_demo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Demo folder successfully uploaded with commit URL: https://huggingface.co/spaces/LizzChall/food_not_food_text_classifier_demo/tree/main/.\n"
          ]
        }
      ],
      "source": [
        "# 1. Import the required methods for uploading to the HF Hub\n",
        "from huggingface_hub import (\n",
        "    create_repo,\n",
        "    get_full_repo_name,\n",
        "    upload_file,\n",
        "    upload_folder\n",
        ")\n",
        "\n",
        "# 2. Define the parameters we'd like to use for uploading our space\n",
        "LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD = \"../demos/food_not_food_text_classifier\"\n",
        "HF_TARGET_SPACE_NAME = \"food_not_food_text_classifier_demo\"\n",
        "HF_REPO_TYPE = \"space\"\n",
        "HF_SPACE_SDK = \"gradio\"\n",
        "\n",
        "# 3. Create a Space Repo on Hugging Face Hub\n",
        "print(f\"[INFO] Creating Space repository on Hugging Face Hub...\")\n",
        "create_repo(\n",
        "    repo_id=HF_TARGET_SPACE_NAME,\n",
        "    repo_type=HF_REPO_TYPE,\n",
        "    private=False,\n",
        "    space_sdk=HF_SPACE_SDK,\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "# 4. Get the full repo name\n",
        "hf_full_repo_name = get_full_repo_name(model_id=HF_TARGET_SPACE_NAME)\n",
        "print(f\"[INFO] Full Hugging Face Hub repo name: {hf_full_repo_name}\")\n",
        "\n",
        "# 5. Upload our demo folder\n",
        "print(f\"[INFO] Uploading {LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD} to repo: {hf_full_repo_name}\")\n",
        "folder_upload_url = upload_folder(\n",
        "    folder_path=LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD,\n",
        "    repo_id=hf_full_repo_name,\n",
        "    repo_type=HF_REPO_TYPE,\n",
        "    path_in_repo=\".\",\n",
        "    commit_message=\"Uploading food not food text classifier demo from a notebook!\"\n",
        ")\n",
        "\n",
        "print(f\"[INFO] Demo folder successfully uploaded with commit URL: {folder_upload_url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK33UPmmuVtp"
      },
      "source": [
        "### Embedding our Hugging Face Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "GdyKXnlheSwV",
        "outputId": "35e633da-8eb1-4146-e6fe-a2a6def42e2e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<iframe\n",
              "\tsrc=\"https://lizzchall-food-not-food-text-classifier-demo.hf.space\"\n",
              "\tframeborder=\"0\"\n",
              "\twidth=\"850\"\n",
              "\theight=\"450\"\n",
              "></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 318,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(data='''\n",
        "<iframe\n",
        "\tsrc=\"https://lizzchall-food-not-food-text-classifier-demo.hf.space\"\n",
        "\tframeborder=\"0\"\n",
        "\twidth=\"850\"\n",
        "\theight=\"450\"\n",
        "></iframe>\n",
        "''')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgS3puDYeX8I"
      },
      "source": [
        "### Saving a backup of notebook before cleaning the metadata to push to github. (just incase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lj-GhgozZGdV"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/MyDrive/Colab Notebooks/huggingface_text_classification.ipynb\" \\\n",
        "   \"/content/drive/MyDrive/Colab Notebooks/huggingface_text_classification_backup.ipynb\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1j5wAG8el4M"
      },
      "source": [
        "### Cleaning Broken Widget Metadata from a Colab Notebook.\n",
        "\n",
        "When commiting this notebook to GitHub we encountered a metadata error.\n",
        "\n",
        "ðŸ’¡ Here is essentially a safe script to \"strip out\" the broken widget metadata so the notebook can open and render correctly.\n",
        "\n",
        "1. Imports `nbformat` â€“ a library to read and write Jupyter notebooks programmatically.\n",
        "\n",
        "2. Specifies the notebook file path on your Google Drive.\n",
        "\n",
        "3. Opens the notebook and loads its content into a Python object (nb).\n",
        "\n",
        "4. Checks for metadata.widgets â€“ this is the part of the notebook metadata causing rendering errors in Colab.\n",
        "\n",
        "5. Removes `metadata.widgets` if it exists, or prints a message if it doesnâ€™t.\n",
        "\n",
        "6. Writes the cleaned notebook back to the same file, overwriting the old version.\n",
        "\n",
        "7. Prints a confirmation once the notebook has been cleaned and saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wfSXvafcDst",
        "outputId": "587aa4ec-5c55-4921-dae0-32309059b9f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 'metadata.widgets' â€” removing it...\n",
            "Notebook metadata cleaned and saved âœ…\n"
          ]
        }
      ],
      "source": [
        "import nbformat\n",
        "\n",
        "# Path to the notebook in Drive\n",
        "notebook_path = \"/content/drive/MyDrive/Colab Notebooks/huggingface_text_classification.ipynb\"\n",
        "\n",
        "# Load the notebook\n",
        "with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    nb = nbformat.read(f, as_version=nbformat.NO_CONVERT)\n",
        "\n",
        "# Clean out the problematic metadata\n",
        "if \"widgets\" in nb.metadata:\n",
        "    print(\"Found 'metadata.widgets' â€” removing it...\")\n",
        "    del nb.metadata[\"widgets\"]\n",
        "else:\n",
        "    print(\"No 'metadata.widgets' found. Nothing to clean.\")\n",
        "\n",
        "# Save cleaned notebook back\n",
        "with open(notebook_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    nbformat.write(nb, f)\n",
        "\n",
        "print(\"Notebook metadata cleaned and saved âœ…\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBNgc0IAu31g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1iD4pqI4Rk6L1bJzyg3uW1SA3FAD0UYqx",
      "authorship_tag": "ABX9TyNcWVQgFVQ/9pbGOAkyrleo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}